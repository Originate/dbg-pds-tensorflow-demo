{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Movement Prediction Using The Deutsche BÃ¶rse Public Dataset & Machine Learning - Notebook 3 (Applying A Neural Network)\n",
    "\n",
    "Here we apply the neural network approach suggested in Notebook 1 to the data set product in Notebook 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: 20 minute by 20 minute predictions\n",
    "\n",
    "We adapt the approaches of notebook `03-stock-price-prediction-machine-learning.ipynb` and\n",
    "notebook `supporting/simple-linear-model.ipynb` to work on 20 minutes by 20 minute basis rather than on a minute by minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (15, 10) # use bigger graphs\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Reshape, Conv1D, MaxPooling1D, BatchNormalization, LeakyReLU\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the file we processed in the second notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/data/cooked_v3.pkl'\n",
    "df = pd.read_pickle(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what stocks are available in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['SNH', 'DBK', 'EOAN', 'DTE', 'CBK', 'RWE', 'IFX', 'SVAB', 'LHA',\n",
       "        'DAI', 'O2D', 'TKA', 'DPW', 'HDD', 'SIE', 'AIXA', 'BAYN', 'SAP',\n",
       "        'BAS', 'EVT', 'AT1', 'PSM', 'BMW', 'VOW3', 'FRE', 'GAZ', 'SDF',\n",
       "        'CEC', 'ALV', 'VNA', 'B4B', 'SHA', 'AB1', 'UN01', 'DLG', 'NDX1',\n",
       "        'NOA3', 'IGY', 'VODI', 'ADS', '1COV', 'TUI1', 'BPE5', 'HEI', 'KCO',\n",
       "        'ADV', 'SZU', 'EVK', 'HEN3', 'WDI', 'MUV2', 'DWNI', 'MRK', 'USE',\n",
       "        'PAH3', 'DEZ', 'FME', 'G1A', 'FNTN', 'RKET', 'QIA', 'DB1', 'ZAL',\n",
       "        'QSC', 'CON', 'SGL', 'BVB', 'TINA', 'PBB', 'PNE3', 'RIB', 'OSR',\n",
       "        'SHL', 'AOX', 'BEI', 'TEG', 'UTDI', 'ARL', 'MDG1', 'KGX', 'LXS',\n",
       "        'ARO', 'TTI', 'SANT', 'GYC', 'ANO', 'LINU', 'SOW', 'SZG', 'LLD',\n",
       "        'BOSS', 'BNR', 'WAF', 'LIN', 'DRI', 'NDA', 'ZIL2', 'SY1', 'CAP',\n",
       "        '3W9K'], dtype=object), 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mnemonics = df.Mnemonic.unique()\n",
    "df.Mnemonic.unique(), df.Mnemonic.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will select the most liquid stocks from this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>LiquidityNormalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIE</th>\n",
       "      <td>3.487777e+10</td>\n",
       "      <td>5.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBK</th>\n",
       "      <td>3.148580e+10</td>\n",
       "      <td>4.991381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALV</th>\n",
       "      <td>3.139013e+10</td>\n",
       "      <td>4.976214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYN</th>\n",
       "      <td>3.100024e+10</td>\n",
       "      <td>4.914406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOW3</th>\n",
       "      <td>3.092967e+10</td>\n",
       "      <td>4.903217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Liquidity  LiquidityNormalized\n",
       "Mnemonic                                   \n",
       "SIE       3.487777e+10             5.529101\n",
       "DBK       3.148580e+10             4.991381\n",
       "ALV       3.139013e+10             4.976214\n",
       "BAYN      3.100024e+10             4.914406\n",
       "VOW3      3.092967e+10             4.903217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Liquidity'] = df['TradedVolume']*df['EndPrice']\n",
    "tmp = df.groupby('Mnemonic')['Liquidity'].sum().to_frame()\n",
    "tmp['LiquidityNormalized'] = 100.0*tmp['Liquidity']/(tmp['Liquidity'].sum())\n",
    "df = df.drop(columns=['Liquidity'])\n",
    "\n",
    "tmp.sort_values('LiquidityNormalized', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Most liquid stocks: SIE, DBK, ALV, BAYN, VOW3, DAI, SAP, BAS, DTE, BMW, ADS, CBK, EOAN, IFX, MUV2, RWE, LHA, CON, DPW, FRE, HEN3, TKA, HEI, 1COV, LINU, WDI, PSM, MRK, DB1, VNA, FME, LIN, PAH3, BEI, WAF, EVT, IGY, SDF, AIXA, OSR, SNH, DLG, KGX, LXS, DWNI, ZAL, G1A, UN01, BOSS, UTDI\n"
     ]
    }
   ],
   "source": [
    "most_liquid_stocks = list(tmp.sort_values('LiquidityNormalized', ascending=False).index[0:50])\n",
    "print \"50 Most liquid stocks:\", \", \".join(most_liquid_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what dates are available in the file. We will split the original set\n",
    "into three parts, train, valid, test based on the dates.\n",
    "If the dates are ordered chronologically, we take the first dates for the test set,\n",
    "then we take the next dates for the validation set and finally we take what is\n",
    "left for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, ['2017-07-03', '2017-07-04'], ['2018-04-26', '2018-04-27'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_part(dt):\n",
    "    return str(dt).split(' ')[0]\n",
    "unique_days = sorted(list(set(map(date_part , list(df.index.unique())))))\n",
    "len(unique_days), unique_days[0:2], unique_days[-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train', 120, 'valid', 10, 'test', 70)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_train = 60.0\n",
    "percent_valid = 5.0\n",
    "percent_test = 100.0 - percent_train - percent_valid\n",
    "\n",
    "offset_train = int(len(unique_days)*percent_train/100.0)\n",
    "offset_test = offset_train + int(len(unique_days)*percent_valid/100.0)\n",
    "\n",
    "train_valid_days = list(set(unique_days[0:offset_test]))\n",
    "\n",
    "np.random.seed(484811945)\n",
    "np.random.shuffle(train_valid_days)\n",
    "\n",
    "train_days = train_valid_days[0:offset_train]\n",
    "valid_days = train_valid_days[offset_train:]\n",
    "test_days = set(unique_days[offset_test:])\n",
    "'train', len(train_days), 'valid', len(valid_days), 'test', len(test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CalcDateTime'] = df.index\n",
    "df['Date'] = df['CalcDateTime'].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.Date.isin(list(train_days))]\n",
    "df_valid = df[df.Date.isin(list(valid_days))]\n",
    "df_test = df[df.Date.isin(list(test_days))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've prepared the train, test and valid sets. Make sure the days do not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>86520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2017-08-09 08:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2017-07-03 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2018-01-09 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count               8652000\n",
       "unique                86520\n",
       "top     2017-08-09 08:10:00\n",
       "freq                    100\n",
       "first   2017-07-03 08:00:00\n",
       "last    2018-01-09 20:00:00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2017-12-29 15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2017-07-05 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2017-12-29 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count                721000\n",
       "unique                 7210\n",
       "top     2017-12-29 15:53:00\n",
       "freq                    100\n",
       "first   2017-07-05 08:00:00\n",
       "last    2017-12-29 20:00:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2018-03-16 10:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2018-01-10 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2018-04-30 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count               5047000\n",
       "unique                50470\n",
       "top     2018-03-16 10:22:00\n",
       "freq                    100\n",
       "first   2018-01-10 08:00:00\n",
       "last    2018-04-30 20:00:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class below we create features from the raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_non_linear_features = True\n",
    "\n",
    "def closer_to_with_normalization(pnt, a, b, norm):\n",
    "    \"\"\"\n",
    "    Returns the \"directed\" and normalized distance to the closer.\n",
    "    @pnt: pnt which is compared to other two points, called a and b here\n",
    "    @a: point a\n",
    "    @b: point b\n",
    "    @norm: normalization constant\n",
    "    \"\"\"    \n",
    "    return (np.absolute(pnt - a) - np.absolute(pnt - b))/norm\n",
    "\n",
    "def resample_single_stock(single_stock, interval):\n",
    "    df = pd.DataFrame({\n",
    "        'MaxPrice': single_stock['MaxPrice'].resample(interval).max(),\n",
    "        'MinPrice': single_stock['MinPrice'].resample(interval).min(),\n",
    "        'LastEndPrice': single_stock['EndPrice'].resample(interval).last(),\n",
    "        'FirstStartPrice': single_stock['StartPrice'].resample(interval).first(),         \n",
    "        'MeanEndPrice': single_stock['EndPrice'].resample(interval).mean(),        \n",
    "        'HasTrade': single_stock['HasTrade'].resample(interval).max(),\n",
    "        'Mnemonic': single_stock['Mnemonic'].resample(interval).last(),\n",
    "        'Date': single_stock['Date'].resample(interval).last(),        \n",
    "    })\n",
    "    \n",
    "    # Warning: this works because we had forward filled the prices\n",
    "    df = df[df['HasTrade'] == 1.0]\n",
    "    return df\n",
    "\n",
    "def rev_pct_change(a, t):\n",
    "    one_step_in_past = a\n",
    "    t_steps_in_past = a.shift(t).ffill()\n",
    "    return ((one_step_in_past - t_steps_in_past)/one_step_in_past).fillna(0.0)\n",
    "\n",
    "def add_non_linear_features(main, resampled, interval):\n",
    "    main['tmp:SignDirection@' + interval] = np.sign(main['x:Direction@' + interval])\n",
    "\n",
    "    main['tmp:D1@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == 1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == 1.0), 1.0, 0.0)\n",
    "\n",
    "    main['tmp:D2@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == -1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == -1.0), -1.0, 0.0)        \n",
    "\n",
    "    main['x:D@' + interval] = main['tmp:D1@' + interval] + main['tmp:D2@' + interval]\n",
    "\n",
    "    main['x:SignDirection-2@' + interval] = np.sign(\n",
    "        (resampled['LastEndPrice'] - resampled['FirstStartPrice'].shift(2).ffill()\n",
    "    )).fillna(0.0)\n",
    "\n",
    "    main['tmp:D1@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == 1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == -1.0), main['x:SignDirection-2@' + interval], 0.0)\n",
    "\n",
    "    main['tmp:D2@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == -1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == 1.0), main['x:SignDirection-2@' + interval], 0.0)        \n",
    "\n",
    "    main['x:Da@' + interval] = main['tmp:D1@' + interval] + main['tmp:D2@' + interval]\n",
    "    \n",
    "    main = main.drop(columns=[\n",
    "        'tmp:SignDirection@' + interval,\n",
    "        'tmp:D1@' + interval,\n",
    "        'tmp:D2@' + interval\n",
    "    ])\n",
    "        \n",
    "    return main\n",
    "\n",
    "def prepare_single_stock_multi_intervals(single_stock, predicted_price, main_interval, intervals):\n",
    "        \n",
    "    main = resample_single_stock(single_stock, main_interval)\n",
    "    # we use the same anchor\n",
    "    anchor = main['MeanEndPrice']\n",
    "    future_mean_price = main[predicted_price].shift(-1)\n",
    "    \n",
    "    main['y(Return)'] = (future_mean_price - anchor)/anchor\n",
    "\n",
    "    # do not normalize\n",
    "    main['pseudo_y(SignReturn)'] = np.sign(main['y(Return)'])\n",
    "\n",
    "    # actual return won't be normalized\n",
    "    main['pseudo_y(pctChange)'] = (future_mean_price - anchor)/anchor\n",
    "    \n",
    "    # baseline will be normalized\n",
    "    main['baseline'] = main['pseudo_y(pctChange)'].shift(1).fillna(0.0)    \n",
    "    \n",
    "    all_intervals = [main_interval] + intervals\n",
    "    \n",
    "    for interval in all_intervals:\n",
    "        sub = resample_single_stock(single_stock, interval)\n",
    "        resampled = sub.resample(main_interval).last() \n",
    "\n",
    "        main['x:Direction@' + interval] = \\\n",
    "            2.0*(resampled['LastEndPrice'] - resampled['FirstStartPrice'])/ \\\n",
    "            anchor\n",
    "\n",
    "        if enable_non_linear_features:\n",
    "            main = add_non_linear_features(main, resampled, interval)\n",
    "\n",
    "        main['x:H1@' + interval] = - closer_to_with_normalization(\n",
    "                                                 resampled['LastEndPrice'], \n",
    "                                                 resampled['MaxPrice'], \n",
    "                                                 resampled['MinPrice'],\n",
    "                                                 anchor)    \n",
    "        \n",
    "        main['x:EndToMean@' + interval] = (resampled['LastEndPrice'] - resampled['MeanEndPrice'])/anchor\n",
    "        \n",
    "        main['x:AdjustedPctChange@' + interval] = (resampled['LastEndPrice'] - resampled['MeanEndPrice'])/resampled['MeanEndPrice']\n",
    "        main['x:RevPctChange@' + interval] = rev_pct_change(resampled['LastEndPrice'], 1)\n",
    "    \n",
    "    main = main[main['HasTrade'] == 1.0]\n",
    "    meta = main[['MeanEndPrice', 'HasTrade', 'LastEndPrice']]\n",
    "    main = main.drop(columns = [\n",
    "        'MaxPrice',\n",
    "        'MinPrice',\n",
    "        'LastEndPrice',\n",
    "        'FirstStartPrice',         \n",
    "        'MeanEndPrice',     \n",
    "        'HasTrade'       \n",
    "    ])\n",
    "    return main, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NARemover:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def transform(self, single_stock):\n",
    "        before = single_stock.shape[0]\n",
    "        single_stock = single_stock.dropna()\n",
    "        after = single_stock.shape[0]\n",
    "        print(\"{}: Dropped {:2.2f} % of records due to NA\".format(self.name, 100.0*(before - after)/(0.0001 + before)))\n",
    "        return single_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable we use for predictions start with `x(`, while the variables that should be predicted start with `y(`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>y(Return)</th>\n",
       "      <th>pseudo_y(SignReturn)</th>\n",
       "      <th>pseudo_y(pctChange)</th>\n",
       "      <th>baseline</th>\n",
       "      <th>x:Direction@20Min</th>\n",
       "      <th>x:D@20Min</th>\n",
       "      <th>x:SignDirection-2@20Min</th>\n",
       "      <th>x:Da@20Min</th>\n",
       "      <th>...</th>\n",
       "      <th>x:AdjustedPctChange@5Min</th>\n",
       "      <th>x:RevPctChange@5Min</th>\n",
       "      <th>x:Direction@10Min</th>\n",
       "      <th>x:D@10Min</th>\n",
       "      <th>x:SignDirection-2@10Min</th>\n",
       "      <th>x:Da@10Min</th>\n",
       "      <th>x:H1@10Min</th>\n",
       "      <th>x:EndToMean@10Min</th>\n",
       "      <th>x:AdjustedPctChange@10Min</th>\n",
       "      <th>x:RevPctChange@10Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalcDateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:00:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:20:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:40:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.001336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 09:00:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.002918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>-0.002918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.001582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 09:20:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date Mnemonic  y(Return)  pseudo_y(SignReturn)  \\\n",
       "CalcDateTime                                                                \n",
       "2017-07-03 08:00:00  2017-07-03      BMW   0.002151                   1.0   \n",
       "2017-07-03 08:20:00  2017-07-03      BMW   0.001739                   1.0   \n",
       "2017-07-03 08:40:00  2017-07-03      BMW  -0.000097                  -1.0   \n",
       "2017-07-03 09:00:00  2017-07-03      BMW  -0.000109                  -1.0   \n",
       "2017-07-03 09:20:00  2017-07-03      BMW   0.000863                   1.0   \n",
       "\n",
       "                     pseudo_y(pctChange)  baseline  x:Direction@20Min  \\\n",
       "CalcDateTime                                                            \n",
       "2017-07-03 08:00:00             0.002151  0.000000           0.000488   \n",
       "2017-07-03 08:20:00             0.001739  0.002151           0.005845   \n",
       "2017-07-03 08:40:00            -0.000097  0.001739           0.002918   \n",
       "2017-07-03 09:00:00            -0.000109 -0.000097          -0.002918   \n",
       "2017-07-03 09:20:00             0.000863 -0.000109           0.001702   \n",
       "\n",
       "                     x:D@20Min  x:SignDirection-2@20Min  x:Da@20Min  \\\n",
       "CalcDateTime                                                          \n",
       "2017-07-03 08:00:00        0.0                      0.0         0.0   \n",
       "2017-07-03 08:20:00        1.0                      0.0         0.0   \n",
       "2017-07-03 08:40:00        1.0                      1.0         0.0   \n",
       "2017-07-03 09:00:00        0.0                      1.0         1.0   \n",
       "2017-07-03 09:20:00        0.0                      1.0         1.0   \n",
       "\n",
       "                             ...           x:AdjustedPctChange@5Min  \\\n",
       "CalcDateTime                 ...                                      \n",
       "2017-07-03 08:00:00          ...                           0.000000   \n",
       "2017-07-03 08:20:00          ...                          -0.000146   \n",
       "2017-07-03 08:40:00          ...                           0.000170   \n",
       "2017-07-03 09:00:00          ...                           0.000438   \n",
       "2017-07-03 09:20:00          ...                          -0.000073   \n",
       "\n",
       "                     x:RevPctChange@5Min  x:Direction@10Min  x:D@10Min  \\\n",
       "CalcDateTime                                                             \n",
       "2017-07-03 08:00:00             0.000000           0.000488        0.0   \n",
       "2017-07-03 08:20:00             0.002919           0.002436        1.0   \n",
       "2017-07-03 08:40:00             0.001336           0.002675        1.0   \n",
       "2017-07-03 09:00:00            -0.001582          -0.002918        0.0   \n",
       "2017-07-03 09:20:00             0.000851           0.001702        0.0   \n",
       "\n",
       "                     x:SignDirection-2@10Min  x:Da@10Min  x:H1@10Min  \\\n",
       "CalcDateTime                                                           \n",
       "2017-07-03 08:00:00                      0.0         0.0    0.000976   \n",
       "2017-07-03 08:20:00                      0.0         0.0    0.001096   \n",
       "2017-07-03 08:40:00                      1.0         0.0    0.001216   \n",
       "2017-07-03 09:00:00                      1.0         1.0   -0.000486   \n",
       "2017-07-03 09:20:00                      1.0         1.0    0.000608   \n",
       "\n",
       "                     x:EndToMean@10Min  x:AdjustedPctChange@10Min  \\\n",
       "CalcDateTime                                                        \n",
       "2017-07-03 08:00:00           0.000439                   0.000439   \n",
       "2017-07-03 08:20:00           0.000379                   0.000379   \n",
       "2017-07-03 08:40:00           0.000413                   0.000413   \n",
       "2017-07-03 09:00:00          -0.000012                  -0.000012   \n",
       "2017-07-03 09:20:00          -0.000036                  -0.000036   \n",
       "\n",
       "                     x:RevPctChange@10Min  \n",
       "CalcDateTime                               \n",
       "2017-07-03 08:00:00              0.000000  \n",
       "2017-07-03 08:20:00              0.002919  \n",
       "2017-07-03 08:40:00              0.001336  \n",
       "2017-07-03 09:00:00             -0.001582  \n",
       "2017-07-03 09:20:00              0.000851  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = df_train[df_train.Mnemonic == 'BMW'].copy()\n",
    "dummy = dummy[dummy.HasTrade == 1.0]\n",
    "#main_interval_dummy, intervals_dummy = '20Min', ['5Min', '10Min', '15Min']\n",
    "main_interval_dummy, intervals_dummy = '20Min', ['5Min', '10Min']\n",
    "\n",
    "dummy, meta = prepare_single_stock_multi_intervals(dummy, 'MeanEndPrice', main_interval_dummy, intervals_dummy)\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSet:\n",
    "    def __init__(self, X, y, orig_df):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.baseline = orig_df['baseline'].values\n",
    "        self.original_df = orig_df\n",
    "        \n",
    "class TrainingSetBuilder:\n",
    "    def transform(self, single_stock):\n",
    "        x_features = filter(lambda name: name.startswith('x(') or name.startswith('x:'), list(single_stock.dtypes.index))\n",
    "        X = single_stock[x_features].values\n",
    "        y = single_stock[['pseudo_y(SignReturn)']].values \n",
    "        return TrainingSet(X, y, single_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    def __init__(self, predictions, training_set):\n",
    "\n",
    "        self.predictions = predictions\n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def evaluate(self):\n",
    "        single_feature = 'baseline'\n",
    "        stats_df = pd.DataFrame({\n",
    "                      'predictions': self.predictions[:,0],\n",
    "                      'single_feature_pred': self.training_set.original_df[single_feature].values,\n",
    "                      'pseudo_y(SignReturn)': self.training_set.y[:,0],\n",
    "                      'pseudo_y(pctChange)': self.training_set.original_df['pseudo_y(pctChange)'].values,\n",
    "                      'y(Return)': self.training_set.original_df['y(Return)'].values})\n",
    "        \n",
    "        corr = stats_df. \\\n",
    "            corr()[['predictions', 'single_feature_pred']]. \\\n",
    "            iloc[1:]\n",
    "            \n",
    "        pred_signs = np.sign(stats_df['predictions'])\n",
    "        y_signs = np.sign(stats_df['y(Return)'])\n",
    "        has_answer = np.absolute(pred_signs * y_signs).sum()\n",
    "        correct = np.where(pred_signs * y_signs == 1.0, 1.0, 0.0).sum()\n",
    "        \n",
    "        thresholds = []\n",
    "        accuracy = []\n",
    "        correct_lst = []\n",
    "        errors = []\n",
    "        percent_has_answer = []\n",
    "        abs_has_answer = []\n",
    "        achieved_returns = []\n",
    "\n",
    "        preds = stats_df['predictions']\n",
    "        \n",
    "        for d in range(5, 46, 5):\n",
    "            low = np.percentile(preds, d) \n",
    "            high = np.percentile(preds, 100 - d)\n",
    "            thresholded = np.where(preds > high, 1.0, np.where(preds < low, -1.0, 0.0))\n",
    "            c = np.where(np.sign(thresholded)*np.sign(y_signs) == 1.0, 1.0, 0.0).sum()\n",
    "            e = np.where(np.sign(thresholded)*np.sign(y_signs) == -1.0, 1.0, 0.0).sum()\n",
    "            achieved_ret = (stats_df['pseudo_y(pctChange)']*thresholded).sum()\n",
    "            correct_lst.append(c)\n",
    "            errors.append(e)\n",
    "            accuracy.append(c/(c + e))\n",
    "            percent_has_answer.append(100.0*(c + e)/pred_signs.shape[0])\n",
    "            abs_has_answer.append((c + e))\n",
    "            achieved_returns.append(achieved_ret)\n",
    "            thresholds.append(d)\n",
    "            \n",
    "        at_cutoff = DataFrame({\n",
    "                    'thresholds': thresholds,\n",
    "                    'accuracy': accuracy,\n",
    "                    'percent_with_answer': percent_has_answer,\n",
    "                    'absolute_has_answer': abs_has_answer,\n",
    "                    'achieved_returns': achieved_returns,\n",
    "                    'correct': correct_lst,\n",
    "                    'errors': errors\n",
    "        })\n",
    "        at_cutoff['achieved_norm_returns'] = at_cutoff['achieved_returns']/at_cutoff['absolute_has_answer']\n",
    "        \n",
    "        ret = stats_df['pseudo_y(pctChange)']\n",
    "        rand_feature = np.where(np.random.rand(ret.shape[0]) > 0.5, 1.0, -1.0)    \n",
    "        random_returns = (ret * rand_feature).sum()\n",
    "        always_up_returns = (ret*1.0).sum()\n",
    "        always_down_returns = (ret*-1.0).sum()\n",
    "        omnicient_returns = (np.absolute(ret)).sum()\n",
    "        achieved = (ret * pred_signs).sum()\n",
    "        return {\n",
    "            'corr': corr,\n",
    "            'accuracy_at_cutoff': at_cutoff,\n",
    "            'matches': {\n",
    "                'percent_correct': 100*correct/has_answer,\n",
    "                'percent_has_answer': has_answer/pred_signs.shape[0],\n",
    "                'absolute_with_answer': has_answer,\n",
    "                'size': pred_signs.shape[0]\n",
    "            },\n",
    "            'strategies': {\n",
    "                'omniscient': omnicient_returns,\n",
    "                'random': random_returns,\n",
    "                'always_up': always_up_returns,\n",
    "                'always_down': always_down_returns,\n",
    "                'achieved': achieved,\n",
    "                'num_trials': np.absolute(pred_signs).sum()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "class MLModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, training_set, valid_set = None):\n",
    "        train_X, train_y = training_set.X, training_set.y\n",
    "        \n",
    "        if valid_set is None:\n",
    "            valid_X, valid_y = train_X, train_y\n",
    "        else:\n",
    "            valid_X, valid_y = valid_set.X, valid_set.y\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(10, activation='relu', input_shape =(train_X.shape[1],),\n",
    "                        kernel_regularizer=regularizers.l2(0.1))) \n",
    "        model.add(Dense(5, activation='relu', kernel_regularizer=regularizers.l2(0.1)))        \n",
    "\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        self.model = model            \n",
    "\n",
    "        # fit network\n",
    "        history = model.fit(train_X, train_y, epochs=150, batch_size=2500, validation_data=(valid_X, valid_y), verbose=2, shuffle=True)\n",
    "        # plot history\n",
    "        pyplot.plot(history.history['loss'], label='train')\n",
    "        pyplot.plot(history.history['val_loss'], label='valid')\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "        \n",
    "    def transform(self, input_set):\n",
    "        predictions = self.model.predict(input_set.X)\n",
    "        return Predictions(predictions, input_set)\n",
    "    \n",
    "    def fit_transform(self, training_set, valid_set):\n",
    "        self.fit(training_set, valid_set)\n",
    "        return self.transform(training_set), self.transform(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inverter(m, s, th):\n",
    "    return lambda y: y*s + m\n",
    "\n",
    "def make_transformer(m, s, th):\n",
    "    def transform(fn):\n",
    "        norm = (fn-m)/s\n",
    "        return np.where(norm > th, th, np.where(norm < -th, -th, norm))\n",
    "    return transform\n",
    "\n",
    "def fit_normalize_features(prepared_single_stock):\n",
    "    th = 2.5  \n",
    "    inp = prepared_single_stock.copy()\n",
    "    inverters = {}\n",
    "    transformers = {}\n",
    "    \n",
    "    for f in list(inp.dtypes.index):\n",
    "        if f.startswith('x(') or f.startswith('x:') or f == 'baseline':\n",
    "            fn = inp[f]\n",
    "            s = 0.0000001 + np.std(fn.values)\n",
    "            m = np.mean(fn.values)\n",
    "\n",
    "            inverters[f] = make_inverter(m, s, th)\n",
    "            transformers[f] = make_transformer(m, s, th)\n",
    "            inp[f] = transformers[f](fn)\n",
    "        \n",
    "    return inp, transformers, inverters\n",
    "\n",
    "def normalize_features(prepared_single_stock, transformers):\n",
    "    inp = prepared_single_stock.copy()    \n",
    "    for f in list(inp.dtypes.index):\n",
    "        if f.startswith('x(') or f.startswith('x:') or f == 'baseline':\n",
    "            fn = inp[f]\n",
    "            inp[f] = transformers[f](fn)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIE: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "SIE: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "SIE: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DBK: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "DBK: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "DBK: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "ALV: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "ALV: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "ALV: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "BAYN: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "BAYN: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "BAYN: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "VOW3: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "VOW3: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "VOW3: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DAI: Dropped 0.04 % of records due to NA\n",
      "('train', (2852, 30))\n",
      "DAI: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "DAI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "SAP: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "SAP: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "SAP: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "BAS: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "BAS: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "BAS: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DTE: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "DTE: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "DTE: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "BMW: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "BMW: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "BMW: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "ADS: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "ADS: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "ADS: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "CBK: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "CBK: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "CBK: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "EOAN: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "EOAN: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "EOAN: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "IFX: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "IFX: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "IFX: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "MUV2: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "MUV2: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "MUV2: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "RWE: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "RWE: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "RWE: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "LHA: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "LHA: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "LHA: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "CON: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "CON: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "CON: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DPW: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "DPW: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "DPW: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "FRE: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "FRE: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "FRE: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "HEN3: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "HEN3: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "HEN3: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "TKA: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "TKA: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "TKA: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "HEI: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "HEI: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "HEI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "1COV: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "1COV: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "1COV: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "LINU: Dropped 0.07 % of records due to NA\n",
      "('train', (1493, 30))\n",
      "LINU: Dropped 1.19 % of records due to NA\n",
      "('valid', (83, 30))\n",
      "LINU: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "WDI: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "WDI: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "WDI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "PSM: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "PSM: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "PSM: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "MRK: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "MRK: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "MRK: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DB1: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "DB1: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "DB1: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "VNA: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "VNA: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "VNA: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "FME: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "FME: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "FME: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "LIN: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "LIN: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "LIN: Dropped 0.06 % of records due to NA\n",
      "('test', (1749, 30))\n",
      "PAH3: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "PAH3: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "PAH3: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "BEI: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "BEI: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "BEI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "WAF: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "WAF: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "WAF: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "EVT: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "EVT: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "EVT: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "IGY: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "IGY: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "IGY: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "SDF: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "SDF: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "SDF: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "AIXA: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "AIXA: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "AIXA: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "OSR: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "OSR: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "OSR: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "SNH: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "SNH: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "SNH: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "DLG: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "DLG: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "DLG: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "KGX: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "KGX: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "KGX: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "LXS: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "LXS: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "LXS: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWNI: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "DWNI: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "DWNI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "ZAL: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "ZAL: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "ZAL: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "G1A: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "G1A: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "G1A: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "UN01: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "UN01: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "UN01: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "BOSS: Dropped 0.04 % of records due to NA\n",
      "('train', (2851, 30))\n",
      "BOSS: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 30))\n",
      "BOSS: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "UTDI: Dropped 0.04 % of records due to NA\n",
      "('train', (2849, 30))\n",
      "UTDI: Dropped 0.44 % of records due to NA\n",
      "('valid', (227, 30))\n",
      "UTDI: Dropped 0.06 % of records due to NA\n",
      "('test', (1757, 30))\n",
      "(141179, 30) (11221, 30) (87842, 30)\n"
     ]
    }
   ],
   "source": [
    "combined_training_set = []\n",
    "combined_valid_set = []\n",
    "combined_test_set = []\n",
    "\n",
    "#main_interval, intervals = '20Min', ['5Min', '10Min', '15Min']\n",
    "main_interval, intervals = '20Min', ['5Min', '10Min']\n",
    "#main_interval, intervals = '4H', ['30Min', '1H', '2H']\n",
    "\n",
    "normalizers = {}\n",
    "\n",
    "for mnemonic in most_liquid_stocks:\n",
    "    single_stock = df_train[df_train.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0]\n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock, single_stock_transformer, _ = fit_normalize_features(single_stock)\n",
    "    normalizers[mnemonic] = single_stock_transformer\n",
    "    \n",
    "    combined_training_set.append(single_stock)\n",
    "    print(\"train\", single_stock.shape)\n",
    "    \n",
    "    single_stock = df_valid[df_valid.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0] \n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock = normalize_features(single_stock, normalizers[mnemonic])\n",
    "    \n",
    "    combined_valid_set.append(single_stock)\n",
    "    print(\"valid\", single_stock.shape)    \n",
    "    \n",
    "    single_stock = df_test[df_test.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0] \n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock = normalize_features(single_stock, normalizers[mnemonic])\n",
    "    combined_test_set.append(single_stock)\n",
    "    print(\"test\", single_stock.shape) \n",
    "    \n",
    "combined_training_set_df = pd.concat(combined_training_set, axis=0)\n",
    "training_set = TrainingSetBuilder().transform(combined_training_set_df)\n",
    "    \n",
    "combined_valid_set_df = pd.concat(combined_valid_set, axis=0)\n",
    "valid_set = TrainingSetBuilder().transform(combined_valid_set_df) \n",
    "\n",
    "combined_test_set_df = pd.concat(combined_test_set, axis=0)\n",
    "test_set = TrainingSetBuilder().transform(combined_test_set_df) \n",
    "    \n",
    "print training_set.original_df.shape, valid_set.original_df.shape,  test_set.original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "class LinearModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, training_set, valid_set = None):\n",
    "        train_X, train_y = training_set.X[:,:], training_set.y\n",
    "        \n",
    "        if valid_set is None:\n",
    "            valid_X, valid_y = train_X, train_y\n",
    "        else:\n",
    "            valid_X, valid_y = valid_set.X, valid_set.y\n",
    "            \n",
    "        self.model = Ridge(alpha=1.5)\n",
    "        # train_y should be -1/+1\n",
    "        self.model.fit(train_X, train_y)\n",
    "       \n",
    "\n",
    "    def transform(self, input_set):\n",
    "        return Predictions(self.model.predict(input_set.X), input_set)\n",
    "    \n",
    "    def fit_transform(self, training_set, valid_set):\n",
    "        self.fit(training_set, valid_set)\n",
    "        return self.transform(training_set), self.transform(valid_set)    \n",
    "\n",
    "model = LinearModel()\n",
    "train_predictions, valid_predictions = model.fit_transform(training_set, valid_set)\n",
    "print \"fitted model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 141082.0,\n",
       " 'percent_correct': 71.42441984094357,\n",
       " 'percent_has_answer': 0.9993129289766892,\n",
       " 'size': 141179}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 11214.0,\n",
       " 'percent_correct': 71.02728731942216,\n",
       " 'percent_has_answer': 0.9993761696818465,\n",
       " 'size': 11221}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 87787.0,\n",
       " 'percent_correct': 71.52084021552166,\n",
       " 'percent_has_answer': 0.9993738758224995,\n",
       " 'size': 87842}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.transform(test_set)\n",
    "test_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14116.0</td>\n",
       "      <td>0.918886</td>\n",
       "      <td>40.516371</td>\n",
       "      <td>12971.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>9.998654</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28228.0</td>\n",
       "      <td>0.892731</td>\n",
       "      <td>62.166777</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>3028.0</td>\n",
       "      <td>19.994475</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42339.0</td>\n",
       "      <td>0.869199</td>\n",
       "      <td>78.495138</td>\n",
       "      <td>36801.0</td>\n",
       "      <td>5538.0</td>\n",
       "      <td>29.989588</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56451.0</td>\n",
       "      <td>0.845831</td>\n",
       "      <td>91.146567</td>\n",
       "      <td>47748.0</td>\n",
       "      <td>8703.0</td>\n",
       "      <td>39.985409</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70567.0</td>\n",
       "      <td>0.822311</td>\n",
       "      <td>101.015165</td>\n",
       "      <td>58028.0</td>\n",
       "      <td>12539.0</td>\n",
       "      <td>49.984063</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84673.0</td>\n",
       "      <td>0.799428</td>\n",
       "      <td>108.143428</td>\n",
       "      <td>67690.0</td>\n",
       "      <td>16983.0</td>\n",
       "      <td>59.975634</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>98779.0</td>\n",
       "      <td>0.777139</td>\n",
       "      <td>114.041767</td>\n",
       "      <td>76765.0</td>\n",
       "      <td>22014.0</td>\n",
       "      <td>69.967205</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112887.0</td>\n",
       "      <td>0.756252</td>\n",
       "      <td>117.648339</td>\n",
       "      <td>85371.0</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>79.960192</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126993.0</td>\n",
       "      <td>0.735568</td>\n",
       "      <td>119.750500</td>\n",
       "      <td>93412.0</td>\n",
       "      <td>33581.0</td>\n",
       "      <td>89.951763</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0              14116.0  0.918886         40.516371  12971.0   1145.0   \n",
       "1              28228.0  0.892731         62.166777  25200.0   3028.0   \n",
       "2              42339.0  0.869199         78.495138  36801.0   5538.0   \n",
       "3              56451.0  0.845831         91.146567  47748.0   8703.0   \n",
       "4              70567.0  0.822311        101.015165  58028.0  12539.0   \n",
       "5              84673.0  0.799428        108.143428  67690.0  16983.0   \n",
       "6              98779.0  0.777139        114.041767  76765.0  22014.0   \n",
       "7             112887.0  0.756252        117.648339  85371.0  27516.0   \n",
       "8             126993.0  0.735568        119.750500  93412.0  33581.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.998654           5               0.002870  \n",
       "1            19.994475          10               0.002202  \n",
       "2            29.989588          15               0.001854  \n",
       "3            39.985409          20               0.001615  \n",
       "4            49.984063          25               0.001431  \n",
       "5            59.975634          30               0.001277  \n",
       "6            69.967205          35               0.001155  \n",
       "7            79.960192          40               0.001042  \n",
       "8            89.951763          45               0.000943  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So if you play 141179 times on the Training Set with 1 EUR and you always guess the movement,\n",
      "ignoring all transactions cost, you will make 225.901402577. \n",
      "Instead you make 121.438640436 or 53.7573645188 percent of the ideally achievable.\n",
      "If you use the baseline you will make 43.7005024166 or 19.3449451478 percent of ideal\n"
     ]
    }
   ],
   "source": [
    "def pred_baseline(d):\n",
    "    single_feature = 'baseline'\n",
    "    preds = d.training_set.original_df[single_feature].values\n",
    "    preds = preds.reshape((preds.shape[0], 1))\n",
    "    return Predictions(preds, d.training_set).evaluate()\n",
    "\n",
    "def readable_summary(which_set, p):\n",
    "    achieved = p.evaluate()['strategies']['achieved']\n",
    "    achieved_baseline = pred_baseline(p)['strategies']['achieved']\n",
    "    per_change = np.mean(np.absolute(p.training_set.original_df['pseudo_y(pctChange)']))\n",
    "    n = p.training_set.original_df.shape[0]\n",
    "    print (\"\"\"So if you play {} times on the {} with 1 EUR and you always guess the movement,\n",
    "ignoring all transactions cost, you will make {}. \n",
    "Instead you make {} or {} percent of the ideally achievable.\n",
    "If you use the baseline you will make {} or {} percent of ideal\"\"\".format(\n",
    "        n, which_set, n * per_change, achieved, 100.0*achieved/(n*per_change),\n",
    "          achieved_baseline, 100.0*achieved_baseline/(n*per_change)))\n",
    "readable_summary('Training Set', train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 121.43864043621069,\n",
       " 'always_down': -5.61173357331636,\n",
       " 'always_up': 5.61173357331636,\n",
       " 'num_trials': 141179.0,\n",
       " 'omniscient': 225.90140257657504,\n",
       " 'random': -1.4828107269312116}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['strategies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 4.5802918780178,\n",
       " 'always_down': -3.8572299663272602,\n",
       " 'always_up': 3.8572299663272602,\n",
       " 'num_trials': 11221.0,\n",
       " 'omniscient': 32.09928307576729,\n",
       " 'random': -0.9994415245435728}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_baseline(valid_predictions)['strategies'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1122.0</td>\n",
       "      <td>0.912656</td>\n",
       "      <td>2.262706</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>9.999109</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2244.0</td>\n",
       "      <td>0.885472</td>\n",
       "      <td>3.185007</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>19.998218</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3366.0</td>\n",
       "      <td>0.862151</td>\n",
       "      <td>4.700091</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>29.997326</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4488.0</td>\n",
       "      <td>0.837790</td>\n",
       "      <td>5.927478</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>39.996435</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5610.0</td>\n",
       "      <td>0.816934</td>\n",
       "      <td>6.906141</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>49.995544</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6732.0</td>\n",
       "      <td>0.792781</td>\n",
       "      <td>7.715566</td>\n",
       "      <td>5337.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>59.994653</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7852.0</td>\n",
       "      <td>0.772797</td>\n",
       "      <td>8.133692</td>\n",
       "      <td>6068.0</td>\n",
       "      <td>1784.0</td>\n",
       "      <td>69.975938</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8974.0</td>\n",
       "      <td>0.750613</td>\n",
       "      <td>8.407188</td>\n",
       "      <td>6736.0</td>\n",
       "      <td>2238.0</td>\n",
       "      <td>79.975047</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10093.0</td>\n",
       "      <td>0.729119</td>\n",
       "      <td>8.164960</td>\n",
       "      <td>7359.0</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>89.947420</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct  errors  \\\n",
       "0               1122.0  0.912656          2.262706   1024.0    98.0   \n",
       "1               2244.0  0.885472          3.185007   1987.0   257.0   \n",
       "2               3366.0  0.862151          4.700091   2902.0   464.0   \n",
       "3               4488.0  0.837790          5.927478   3760.0   728.0   \n",
       "4               5610.0  0.816934          6.906141   4583.0  1027.0   \n",
       "5               6732.0  0.792781          7.715566   5337.0  1395.0   \n",
       "6               7852.0  0.772797          8.133692   6068.0  1784.0   \n",
       "7               8974.0  0.750613          8.407188   6736.0  2238.0   \n",
       "8              10093.0  0.729119          8.164960   7359.0  2734.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.999109           5               0.002017  \n",
       "1            19.998218          10               0.001419  \n",
       "2            29.997326          15               0.001396  \n",
       "3            39.996435          20               0.001321  \n",
       "4            49.995544          25               0.001231  \n",
       "5            59.994653          30               0.001146  \n",
       "6            69.975938          35               0.001036  \n",
       "7            79.975047          40               0.000937  \n",
       "8            89.947420          45               0.000809  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline on Testset: Accuracy at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8780.0</td>\n",
       "      <td>0.633030</td>\n",
       "      <td>8.361491</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>3222.0</td>\n",
       "      <td>9.995219</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17561.0</td>\n",
       "      <td>0.630374</td>\n",
       "      <td>15.318856</td>\n",
       "      <td>11070.0</td>\n",
       "      <td>6491.0</td>\n",
       "      <td>19.991576</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26339.0</td>\n",
       "      <td>0.620449</td>\n",
       "      <td>20.989461</td>\n",
       "      <td>16342.0</td>\n",
       "      <td>9997.0</td>\n",
       "      <td>29.984518</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35122.0</td>\n",
       "      <td>0.614088</td>\n",
       "      <td>25.773226</td>\n",
       "      <td>21568.0</td>\n",
       "      <td>13554.0</td>\n",
       "      <td>39.983152</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43900.0</td>\n",
       "      <td>0.605421</td>\n",
       "      <td>29.245495</td>\n",
       "      <td>26578.0</td>\n",
       "      <td>17322.0</td>\n",
       "      <td>49.976093</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52678.0</td>\n",
       "      <td>0.597498</td>\n",
       "      <td>31.925863</td>\n",
       "      <td>31475.0</td>\n",
       "      <td>21203.0</td>\n",
       "      <td>59.969035</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61455.0</td>\n",
       "      <td>0.590237</td>\n",
       "      <td>33.923096</td>\n",
       "      <td>36273.0</td>\n",
       "      <td>25182.0</td>\n",
       "      <td>69.960839</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70236.0</td>\n",
       "      <td>0.582408</td>\n",
       "      <td>35.879759</td>\n",
       "      <td>40906.0</td>\n",
       "      <td>29330.0</td>\n",
       "      <td>79.957196</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79013.0</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>37.065208</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>33477.0</td>\n",
       "      <td>89.948999</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0               8780.0  0.633030          8.361491   5558.0   3222.0   \n",
       "1              17561.0  0.630374         15.318856  11070.0   6491.0   \n",
       "2              26339.0  0.620449         20.989461  16342.0   9997.0   \n",
       "3              35122.0  0.614088         25.773226  21568.0  13554.0   \n",
       "4              43900.0  0.605421         29.245495  26578.0  17322.0   \n",
       "5              52678.0  0.597498         31.925863  31475.0  21203.0   \n",
       "6              61455.0  0.590237         33.923096  36273.0  25182.0   \n",
       "7              70236.0  0.582408         35.879759  40906.0  29330.0   \n",
       "8              79013.0  0.576310         37.065208  45536.0  33477.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.995219           5               0.000952  \n",
       "1            19.991576          10               0.000872  \n",
       "2            29.984518          15               0.000797  \n",
       "3            39.983152          20               0.000734  \n",
       "4            49.976093          25               0.000666  \n",
       "5            59.969035          30               0.000606  \n",
       "6            69.960839          35               0.000552  \n",
       "7            79.957196          40               0.000511  \n",
       "8            89.948999          45               0.000469  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the baseline\n",
    "pred_baseline(test_predictions)['accuracy_at_cutoff'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline on Testset: Comparison of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 37.05529914548468,\n",
       " 'always_down': 4.091329283727091,\n",
       " 'always_up': -4.091329283727091,\n",
       " 'num_trials': 87842.0,\n",
       " 'omniscient': 173.48137595945477,\n",
       " 'random': 1.4202304624958355}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the baseline\n",
    "pred_baseline(test_predictions)['strategies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model on Testset: Accuracy at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8783.0</td>\n",
       "      <td>0.917910</td>\n",
       "      <td>30.075186</td>\n",
       "      <td>8062.0</td>\n",
       "      <td>721.0</td>\n",
       "      <td>9.998634</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17565.0</td>\n",
       "      <td>0.888471</td>\n",
       "      <td>47.423050</td>\n",
       "      <td>15606.0</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>19.996129</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26346.0</td>\n",
       "      <td>0.865596</td>\n",
       "      <td>60.784314</td>\n",
       "      <td>22805.0</td>\n",
       "      <td>3541.0</td>\n",
       "      <td>29.992487</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35123.0</td>\n",
       "      <td>0.843351</td>\n",
       "      <td>71.360378</td>\n",
       "      <td>29621.0</td>\n",
       "      <td>5502.0</td>\n",
       "      <td>39.984290</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43905.0</td>\n",
       "      <td>0.821888</td>\n",
       "      <td>80.238017</td>\n",
       "      <td>36085.0</td>\n",
       "      <td>7820.0</td>\n",
       "      <td>49.981785</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52682.0</td>\n",
       "      <td>0.801033</td>\n",
       "      <td>87.026679</td>\n",
       "      <td>42200.0</td>\n",
       "      <td>10482.0</td>\n",
       "      <td>59.973589</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61457.0</td>\n",
       "      <td>0.779309</td>\n",
       "      <td>92.140384</td>\n",
       "      <td>47894.0</td>\n",
       "      <td>13563.0</td>\n",
       "      <td>69.963116</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70236.0</td>\n",
       "      <td>0.758016</td>\n",
       "      <td>95.346279</td>\n",
       "      <td>53240.0</td>\n",
       "      <td>16996.0</td>\n",
       "      <td>79.957196</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79014.0</td>\n",
       "      <td>0.736287</td>\n",
       "      <td>97.166930</td>\n",
       "      <td>58177.0</td>\n",
       "      <td>20837.0</td>\n",
       "      <td>89.950138</td>\n",
       "      <td>45</td>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0               8783.0  0.917910         30.075186   8062.0    721.0   \n",
       "1              17565.0  0.888471         47.423050  15606.0   1959.0   \n",
       "2              26346.0  0.865596         60.784314  22805.0   3541.0   \n",
       "3              35123.0  0.843351         71.360378  29621.0   5502.0   \n",
       "4              43905.0  0.821888         80.238017  36085.0   7820.0   \n",
       "5              52682.0  0.801033         87.026679  42200.0  10482.0   \n",
       "6              61457.0  0.779309         92.140384  47894.0  13563.0   \n",
       "7              70236.0  0.758016         95.346279  53240.0  16996.0   \n",
       "8              79014.0  0.736287         97.166930  58177.0  20837.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.998634           5               0.003424  \n",
       "1            19.996129          10               0.002700  \n",
       "2            29.992487          15               0.002307  \n",
       "3            39.984290          20               0.002032  \n",
       "4            49.981785          25               0.001828  \n",
       "5            59.973589          30               0.001652  \n",
       "6            69.963116          35               0.001499  \n",
       "7            79.957196          40               0.001358  \n",
       "8            89.950138          45               0.001230  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for ML\n",
    "test_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model on Testset: Comparison of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 97.98783335957789,\n",
       " 'always_down': 4.091329283727091,\n",
       " 'always_up': -4.091329283727091,\n",
       " 'num_trials': 87842.0,\n",
       " 'omniscient': 173.48137595945477,\n",
       " 'random': 1.7567866877165872}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for ML\n",
    "Predictions(test_predictions.predictions, test_predictions.training_set).evaluate()['strategies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So if you play 87842 times on the Test set with 1 EUR and you always guess the movement,\n",
      "ignoring all transactions cost, you will make 173.481375959. \n",
      "Instead you make 97.9878333596 or 56.483200469 percent of the ideally achievable.\n",
      "If you use the baseline you will make 37.0552991455 or 21.3598139515 percent of ideal\n"
     ]
    }
   ],
   "source": [
    "readable_summary('Test set', test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by Mnemonic and by Date\n",
    "\n",
    "It is known that when it comes to stock predictions, different stocks and different days will exibit different performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_by(grouping_feature, predictions):\n",
    "    df = predictions.training_set.original_df\n",
    "    s = df[['Date', 'Mnemonic', 'pseudo_y(SignReturn)']].copy()\n",
    "    s['Predictions'] = predictions.predictions\n",
    "    s['Baseline'] = df['baseline']\n",
    "\n",
    "    def agg(group):\n",
    "        pred = group['Predictions']\n",
    "        baseline = group['Baseline']\n",
    "        rets = group['pseudo_y(SignReturn)']\n",
    "        c = pred.corr(rets)\n",
    "        c = np.where(np.sign(pred)*np.sign(rets) == 1.0, 1.0, 0.0).sum()\n",
    "        e = np.where(np.sign(pred)*np.sign(rets) == -1.0, 1.0, 0.0).sum()\n",
    "        acc = c/(c + e)\n",
    "\n",
    "        c_baseline = np.where(np.sign(baseline)*np.sign(rets) == 1.0, 1.0, 0.0).sum()\n",
    "        e_baseline = np.where(np.sign(baseline)*np.sign(rets) == -1.0, 1.0, 0.0).sum()\n",
    "        acc_baseline = c_baseline/(c_baseline + e_baseline)\n",
    "\n",
    "        l = group.shape[0]\n",
    "        return {\"corr\": c, 'size': l, 'accuracy': acc, 'acc_baseline': acc_baseline}\n",
    "    f = s.groupby(grouping_feature).apply(agg).to_frame(\"agg\")\n",
    "\n",
    "    f['AccuracyPred'] = f['agg'].map(lambda i: i['accuracy'])\n",
    "    f['AccuracyBaseline'] = f['agg'].map(lambda i: i['acc_baseline'])\n",
    "    f['AccPred - AccBaseline'] = f['AccuracyPred'] - f['AccuracyBaseline']\n",
    "    f = f.drop(columns=['agg'])\n",
    "\n",
    "    f = f[f.index != '2017-10-14'] # remove this date which has one data point\n",
    "    f[['AccuracyPred', 'AccuracyBaseline']].plot()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = plot_accuracy_by('Mnemonic', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RWE</th>\n",
       "      <td>0.739898</td>\n",
       "      <td>0.588503</td>\n",
       "      <td>0.151394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS</th>\n",
       "      <td>0.738610</td>\n",
       "      <td>0.564351</td>\n",
       "      <td>0.174260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CON</th>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.541264</td>\n",
       "      <td>0.194650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBK</th>\n",
       "      <td>0.734473</td>\n",
       "      <td>0.562963</td>\n",
       "      <td>0.171510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1COV</th>\n",
       "      <td>0.731777</td>\n",
       "      <td>0.590547</td>\n",
       "      <td>0.141230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.574274</td>\n",
       "      <td>0.155948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRK</th>\n",
       "      <td>0.729499</td>\n",
       "      <td>0.590547</td>\n",
       "      <td>0.138952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TKA</th>\n",
       "      <td>0.729345</td>\n",
       "      <td>0.575499</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBK</th>\n",
       "      <td>0.727945</td>\n",
       "      <td>0.568583</td>\n",
       "      <td>0.159363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOW3</th>\n",
       "      <td>0.727066</td>\n",
       "      <td>0.570370</td>\n",
       "      <td>0.156695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADS</th>\n",
       "      <td>0.726651</td>\n",
       "      <td>0.590547</td>\n",
       "      <td>0.136105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.726651</td>\n",
       "      <td>0.560934</td>\n",
       "      <td>0.165718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FME</th>\n",
       "      <td>0.726238</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>0.148549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYN</th>\n",
       "      <td>0.724530</td>\n",
       "      <td>0.553785</td>\n",
       "      <td>0.170746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNA</th>\n",
       "      <td>0.724374</td>\n",
       "      <td>0.573462</td>\n",
       "      <td>0.150911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAI</th>\n",
       "      <td>0.723804</td>\n",
       "      <td>0.563781</td>\n",
       "      <td>0.160023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTE</th>\n",
       "      <td>0.723489</td>\n",
       "      <td>0.561574</td>\n",
       "      <td>0.161916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAH3</th>\n",
       "      <td>0.723392</td>\n",
       "      <td>0.558338</td>\n",
       "      <td>0.165054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRE</th>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>0.145869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEI</th>\n",
       "      <td>0.721685</td>\n",
       "      <td>0.575982</td>\n",
       "      <td>0.145703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Mnemonic                                                       \n",
       "RWE           0.739898          0.588503               0.151394\n",
       "BAS           0.738610          0.564351               0.174260\n",
       "CON           0.735913          0.541264               0.194650\n",
       "CBK           0.734473          0.562963               0.171510\n",
       "1COV          0.731777          0.590547               0.141230\n",
       "BMW           0.730222          0.574274               0.155948\n",
       "MRK           0.729499          0.590547               0.138952\n",
       "TKA           0.729345          0.575499               0.153846\n",
       "DBK           0.727945          0.568583               0.159363\n",
       "VOW3          0.727066          0.570370               0.156695\n",
       "ADS           0.726651          0.590547               0.136105\n",
       "SAP           0.726651          0.560934               0.165718\n",
       "FME           0.726238          0.577689               0.148549\n",
       "BAYN          0.724530          0.553785               0.170746\n",
       "VNA           0.724374          0.573462               0.150911\n",
       "DAI           0.723804          0.563781               0.160023\n",
       "DTE           0.723489          0.561574               0.161916\n",
       "PAH3          0.723392          0.558338               0.165054\n",
       "FRE           0.723077          0.577208               0.145869\n",
       "HEI           0.721685          0.575982               0.145703"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PSM</th>\n",
       "      <td>0.714855</td>\n",
       "      <td>0.580535</td>\n",
       "      <td>0.134320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSR</th>\n",
       "      <td>0.714692</td>\n",
       "      <td>0.567198</td>\n",
       "      <td>0.147494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1A</th>\n",
       "      <td>0.714692</td>\n",
       "      <td>0.560364</td>\n",
       "      <td>0.154328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WDI</th>\n",
       "      <td>0.714692</td>\n",
       "      <td>0.578588</td>\n",
       "      <td>0.136105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFX</th>\n",
       "      <td>0.713063</td>\n",
       "      <td>0.572732</td>\n",
       "      <td>0.140331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPW</th>\n",
       "      <td>0.709806</td>\n",
       "      <td>0.575257</td>\n",
       "      <td>0.134550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUV2</th>\n",
       "      <td>0.708998</td>\n",
       "      <td>0.550114</td>\n",
       "      <td>0.158884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOSS</th>\n",
       "      <td>0.705581</td>\n",
       "      <td>0.567768</td>\n",
       "      <td>0.137813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIXA</th>\n",
       "      <td>0.704610</td>\n",
       "      <td>0.577689</td>\n",
       "      <td>0.126921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEN3</th>\n",
       "      <td>0.704274</td>\n",
       "      <td>0.574929</td>\n",
       "      <td>0.129345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEI</th>\n",
       "      <td>0.701595</td>\n",
       "      <td>0.580296</td>\n",
       "      <td>0.121298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UTDI</th>\n",
       "      <td>0.700057</td>\n",
       "      <td>0.569721</td>\n",
       "      <td>0.130336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KGX</th>\n",
       "      <td>0.696469</td>\n",
       "      <td>0.557517</td>\n",
       "      <td>0.138952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALV</th>\n",
       "      <td>0.695504</td>\n",
       "      <td>0.557769</td>\n",
       "      <td>0.137735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZAL</th>\n",
       "      <td>0.694935</td>\n",
       "      <td>0.569721</td>\n",
       "      <td>0.125213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LHA</th>\n",
       "      <td>0.691913</td>\n",
       "      <td>0.565490</td>\n",
       "      <td>0.126424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UN01</th>\n",
       "      <td>0.688927</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.122717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IGY</th>\n",
       "      <td>0.683761</td>\n",
       "      <td>0.565812</td>\n",
       "      <td>0.117949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVT</th>\n",
       "      <td>0.678998</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.117814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIN</th>\n",
       "      <td>0.674299</td>\n",
       "      <td>0.554093</td>\n",
       "      <td>0.120206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Mnemonic                                                       \n",
       "PSM           0.714855          0.580535               0.134320\n",
       "OSR           0.714692          0.567198               0.147494\n",
       "G1A           0.714692          0.560364               0.154328\n",
       "WDI           0.714692          0.578588               0.136105\n",
       "IFX           0.713063          0.572732               0.140331\n",
       "DPW           0.709806          0.575257               0.134550\n",
       "MUV2          0.708998          0.550114               0.158884\n",
       "BOSS          0.705581          0.567768               0.137813\n",
       "AIXA          0.704610          0.577689               0.126921\n",
       "HEN3          0.704274          0.574929               0.129345\n",
       "BEI           0.701595          0.580296               0.121298\n",
       "UTDI          0.700057          0.569721               0.130336\n",
       "KGX           0.696469          0.557517               0.138952\n",
       "ALV           0.695504          0.557769               0.137735\n",
       "ZAL           0.694935          0.569721               0.125213\n",
       "LHA           0.691913          0.565490               0.126424\n",
       "UN01          0.688927          0.566210               0.122717\n",
       "IGY           0.683761          0.565812               0.117949\n",
       "EVT           0.678998          0.561184               0.117814\n",
       "LIN           0.674299          0.554093               0.120206"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = plot_accuracy_by('Date', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>0.749347</td>\n",
       "      <td>0.633594</td>\n",
       "      <td>0.115753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>0.749038</td>\n",
       "      <td>0.602771</td>\n",
       "      <td>0.146266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>0.748462</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.179231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-11</th>\n",
       "      <td>0.746923</td>\n",
       "      <td>0.601538</td>\n",
       "      <td>0.145385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>0.745958</td>\n",
       "      <td>0.598152</td>\n",
       "      <td>0.147806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>0.741538</td>\n",
       "      <td>0.604615</td>\n",
       "      <td>0.136923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-09</th>\n",
       "      <td>0.741514</td>\n",
       "      <td>0.586597</td>\n",
       "      <td>0.154917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>0.741140</td>\n",
       "      <td>0.570878</td>\n",
       "      <td>0.170262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.583077</td>\n",
       "      <td>0.155385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>0.736923</td>\n",
       "      <td>0.608462</td>\n",
       "      <td>0.128462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23</th>\n",
       "      <td>0.736154</td>\n",
       "      <td>0.603077</td>\n",
       "      <td>0.133077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24</th>\n",
       "      <td>0.734411</td>\n",
       "      <td>0.564280</td>\n",
       "      <td>0.170131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>0.734411</td>\n",
       "      <td>0.607390</td>\n",
       "      <td>0.127021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>0.733846</td>\n",
       "      <td>0.564615</td>\n",
       "      <td>0.169231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>0.732871</td>\n",
       "      <td>0.508083</td>\n",
       "      <td>0.224788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-25</th>\n",
       "      <td>0.732308</td>\n",
       "      <td>0.546923</td>\n",
       "      <td>0.185385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>0.731125</td>\n",
       "      <td>0.565485</td>\n",
       "      <td>0.165639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>0.729792</td>\n",
       "      <td>0.538876</td>\n",
       "      <td>0.190916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.196923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.154286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Date                                                             \n",
       "2018-04-25      0.749347          0.633594               0.115753\n",
       "2018-03-05      0.749038          0.602771               0.146266\n",
       "2018-02-07      0.748462          0.569231               0.179231\n",
       "2018-01-11      0.746923          0.601538               0.145385\n",
       "2018-01-23      0.745958          0.598152               0.147806\n",
       "2018-02-08      0.741538          0.604615               0.136923\n",
       "2018-04-09      0.741514          0.586597               0.154917\n",
       "2018-03-01      0.741140          0.570878               0.170262\n",
       "2018-03-08      0.738462          0.583077               0.155385\n",
       "2018-01-16      0.736923          0.608462               0.128462\n",
       "2018-02-23      0.736154          0.603077               0.133077\n",
       "2018-01-24      0.734411          0.564280               0.170131\n",
       "2018-02-15      0.734411          0.607390               0.127021\n",
       "2018-01-22      0.733846          0.564615               0.169231\n",
       "2018-03-07      0.732871          0.508083               0.224788\n",
       "2018-01-25      0.732308          0.546923               0.185385\n",
       "2018-02-27      0.731125          0.565485               0.165639\n",
       "2018-02-12      0.729792          0.538876               0.190916\n",
       "2018-03-14      0.726923          0.530000               0.196923\n",
       "2018-04-24      0.724286          0.570000               0.154286"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-18</th>\n",
       "      <td>0.706923</td>\n",
       "      <td>0.546154</td>\n",
       "      <td>0.160769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>0.706697</td>\n",
       "      <td>0.572748</td>\n",
       "      <td>0.133949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-19</th>\n",
       "      <td>0.706697</td>\n",
       "      <td>0.547344</td>\n",
       "      <td>0.159353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-16</th>\n",
       "      <td>0.706190</td>\n",
       "      <td>0.544900</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>0.704931</td>\n",
       "      <td>0.563174</td>\n",
       "      <td>0.141757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>0.704615</td>\n",
       "      <td>0.570769</td>\n",
       "      <td>0.133846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-29</th>\n",
       "      <td>0.701309</td>\n",
       "      <td>0.575058</td>\n",
       "      <td>0.126251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>0.698869</td>\n",
       "      <td>0.577894</td>\n",
       "      <td>0.120975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>0.695000</td>\n",
       "      <td>0.597500</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>0.694380</td>\n",
       "      <td>0.568129</td>\n",
       "      <td>0.126251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-09</th>\n",
       "      <td>0.693077</td>\n",
       "      <td>0.602308</td>\n",
       "      <td>0.090769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19</th>\n",
       "      <td>0.692071</td>\n",
       "      <td>0.575828</td>\n",
       "      <td>0.116243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30</th>\n",
       "      <td>0.689761</td>\n",
       "      <td>0.543495</td>\n",
       "      <td>0.146266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-26</th>\n",
       "      <td>0.687452</td>\n",
       "      <td>0.595843</td>\n",
       "      <td>0.091609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>0.684129</td>\n",
       "      <td>0.547766</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-31</th>\n",
       "      <td>0.681293</td>\n",
       "      <td>0.562741</td>\n",
       "      <td>0.118553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-21</th>\n",
       "      <td>0.678737</td>\n",
       "      <td>0.536210</td>\n",
       "      <td>0.142527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>0.677692</td>\n",
       "      <td>0.558462</td>\n",
       "      <td>0.119231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>0.671018</td>\n",
       "      <td>0.535248</td>\n",
       "      <td>0.135770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-13</th>\n",
       "      <td>0.638183</td>\n",
       "      <td>0.538106</td>\n",
       "      <td>0.100077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Date                                                             \n",
       "2018-01-18      0.706923          0.546154               0.160769\n",
       "2018-01-17      0.706697          0.572748               0.133949\n",
       "2018-02-19      0.706697          0.547344               0.159353\n",
       "2018-04-16      0.706190          0.544900               0.161290\n",
       "2018-02-06      0.704931          0.563174               0.141757\n",
       "2018-03-06      0.704615          0.570769               0.133846\n",
       "2018-01-29      0.701309          0.575058               0.126251\n",
       "2018-04-12      0.698869          0.577894               0.120975\n",
       "2018-03-16      0.695000          0.597500               0.097500\n",
       "2018-01-10      0.694380          0.568129               0.126251\n",
       "2018-02-09      0.693077          0.602308               0.090769\n",
       "2018-01-19      0.692071          0.575828               0.116243\n",
       "2018-01-30      0.689761          0.543495               0.146266\n",
       "2018-02-26      0.687452          0.595843               0.091609\n",
       "2018-03-22      0.684129          0.547766               0.136364\n",
       "2018-01-31      0.681293          0.562741               0.118553\n",
       "2018-02-21      0.678737          0.536210               0.142527\n",
       "2018-03-23      0.677692          0.558462               0.119231\n",
       "2018-04-20      0.671018          0.535248               0.135770\n",
       "2018-02-13      0.638183          0.538106               0.100077"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
