{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Movement Prediction Using The Deutsche Börse Public Dataset & Machine Learning - Notebook 3 (Applying A Neural Network)\n",
    "\n",
    "Here we apply the neural network approach suggested in Notebook 1 to the data set product in Notebook 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important: 20 minute by 20 minute predictions\n",
    "\n",
    "We adapt the approaches of notebook `03-stock-price-prediction-machine-learning.ipynb` and\n",
    "notebook `supporting/simple-linear-model.ipynb` to work on 20 minutes by 20 minute basis rather than on a minute by minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (15, 10) # use bigger graphs\n",
    "\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Reshape, Conv1D, MaxPooling1D, BatchNormalization, LeakyReLU\n",
    "from keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the file we processed in the second notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/data/cooked_v3.pkl'\n",
    "df = pd.read_pickle(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what stocks are available in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['SNH', 'DBK', 'EOAN', 'DTE', 'CBK', 'RWE', 'IFX', 'SVAB', 'LHA',\n",
       "        'DAI', 'O2D', 'TKA', 'DPW', 'HDD', 'SIE', 'AIXA', 'BAYN', 'SAP',\n",
       "        'BAS', 'EVT', 'AT1', 'PSM', 'BMW', 'VOW3', 'FRE', 'GAZ', 'SDF',\n",
       "        'CEC', 'ALV', 'VNA', 'B4B', 'SHA', 'AB1', 'UN01', 'DLG', 'NDX1',\n",
       "        'NOA3', 'IGY', 'VODI', 'ADS', '1COV', 'TUI1', 'BPE5', 'HEI', 'KCO',\n",
       "        'ADV', 'SZU', 'EVK', 'HEN3', 'WDI', 'MUV2', 'DWNI', 'MRK', 'USE',\n",
       "        'PAH3', 'DEZ', 'FME', 'G1A', 'FNTN', 'RKET', 'QIA', 'DB1', 'ZAL',\n",
       "        'QSC', 'CON', 'SGL', 'BVB', 'TINA', 'PBB', 'PNE3', 'RIB', 'OSR',\n",
       "        'SHL', 'AOX', 'BEI', 'TEG', 'UTDI', 'ARL', 'MDG1', 'KGX', 'LXS',\n",
       "        'ARO', 'TTI', 'SANT', 'GYC', 'ANO', 'LINU', 'SOW', 'SZG', 'LLD',\n",
       "        'BOSS', 'BNR', 'WAF', 'LIN', 'DRI', 'NDA', 'ZIL2', 'SY1', 'CAP',\n",
       "        '3W9K'], dtype=object), 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mnemonics = df.Mnemonic.unique()\n",
    "df.Mnemonic.unique(), df.Mnemonic.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will select the most liquid stocks from this set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>LiquidityNormalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SIE</th>\n",
       "      <td>3.487777e+10</td>\n",
       "      <td>5.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBK</th>\n",
       "      <td>3.148580e+10</td>\n",
       "      <td>4.991381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALV</th>\n",
       "      <td>3.139013e+10</td>\n",
       "      <td>4.976214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYN</th>\n",
       "      <td>3.100024e+10</td>\n",
       "      <td>4.914406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOW3</th>\n",
       "      <td>3.092967e+10</td>\n",
       "      <td>4.903217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Liquidity  LiquidityNormalized\n",
       "Mnemonic                                   \n",
       "SIE       3.487777e+10             5.529101\n",
       "DBK       3.148580e+10             4.991381\n",
       "ALV       3.139013e+10             4.976214\n",
       "BAYN      3.100024e+10             4.914406\n",
       "VOW3      3.092967e+10             4.903217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Liquidity'] = df['TradedVolume']*df['EndPrice']\n",
    "tmp = df.groupby('Mnemonic')['Liquidity'].sum().to_frame()\n",
    "tmp['LiquidityNormalized'] = 100.0*tmp['Liquidity']/(tmp['Liquidity'].sum())\n",
    "df = df.drop(columns=['Liquidity'])\n",
    "\n",
    "tmp.sort_values('LiquidityNormalized', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 Most liquid stocks: SIE, DBK, ALV, BAYN, VOW3, DAI, SAP, BAS, DTE, BMW, ADS, CBK, EOAN, IFX, MUV2, RWE, LHA, CON, DPW, FRE, HEN3, TKA, HEI, 1COV, LINU, WDI, PSM, MRK, DB1, VNA, FME, LIN, PAH3, BEI, WAF, EVT, IGY, SDF, AIXA, OSR, SNH, DLG, KGX, LXS, DWNI, ZAL, G1A, UN01, BOSS, UTDI\n"
     ]
    }
   ],
   "source": [
    "most_liquid_stocks = list(tmp.sort_values('LiquidityNormalized', ascending=False).index[0:50])\n",
    "print \"50 Most liquid stocks:\", \", \".join(most_liquid_stocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what dates are available in the file. We will split the original set\n",
    "into three parts, train, valid, test based on the dates.\n",
    "If the dates are ordered chronologically, we take the first dates for the test set,\n",
    "then we take the next dates for the validation set and finally we take what is\n",
    "left for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, ['2017-07-03', '2017-07-04'], ['2018-04-26', '2018-04-27'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def date_part(dt):\n",
    "    return str(dt).split(' ')[0]\n",
    "unique_days = sorted(list(set(map(date_part , list(df.index.unique())))))\n",
    "len(unique_days), unique_days[0:2], unique_days[-3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('train', 120, 'valid', 10, 'test', 70)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_train = 60.0\n",
    "percent_valid = 5.0\n",
    "percent_test = 100.0 - percent_train - percent_valid\n",
    "\n",
    "offset_train = int(len(unique_days)*percent_train/100.0)\n",
    "offset_test = offset_train + int(len(unique_days)*percent_valid/100.0)\n",
    "\n",
    "train_valid_days = list(set(unique_days[0:offset_test]))\n",
    "\n",
    "np.random.seed(484811945)\n",
    "np.random.shuffle(train_valid_days)\n",
    "\n",
    "train_days = train_valid_days[0:offset_train]\n",
    "valid_days = train_valid_days[offset_train:]\n",
    "test_days = set(unique_days[offset_test:])\n",
    "'train', len(train_days), 'valid', len(valid_days), 'test', len(test_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CalcDateTime'] = df.index\n",
    "df['Date'] = df['CalcDateTime'].dt.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df.Date.isin(list(train_days))]\n",
    "df_valid = df[df.Date.isin(list(valid_days))]\n",
    "df_test = df[df.Date.isin(list(test_days))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've prepared the train, test and valid sets. Make sure the days do not overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>86520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2017-08-09 08:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2017-07-03 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2018-01-09 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count               8652000\n",
       "unique                86520\n",
       "top     2017-08-09 08:10:00\n",
       "freq                    100\n",
       "first   2017-07-03 08:00:00\n",
       "last    2018-01-09 20:00:00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2017-12-29 15:53:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2017-07-05 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2017-12-29 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count                721000\n",
       "unique                 7210\n",
       "top     2017-12-29 15:53:00\n",
       "freq                    100\n",
       "first   2017-07-05 08:00:00\n",
       "last    2017-12-29 20:00:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalcDateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>50470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2018-03-16 10:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2018-01-10 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2018-04-30 20:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CalcDateTime\n",
       "count               5047000\n",
       "unique                50470\n",
       "top     2018-03-16 10:22:00\n",
       "freq                    100\n",
       "first   2018-01-10 08:00:00\n",
       "last    2018-04-30 20:00:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['CalcDateTime']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class below we create features from the raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_non_linear_features = True\n",
    "\n",
    "def closer_to_with_normalization(pnt, a, b, norm):\n",
    "    \"\"\"\n",
    "    Returns the \"directed\" and normalized distance to the closer.\n",
    "    @pnt: pnt which is compared to other two points, called a and b here\n",
    "    @a: point a\n",
    "    @b: point b\n",
    "    @norm: normalization constant\n",
    "    \"\"\"    \n",
    "    return (np.absolute(pnt - a) - np.absolute(pnt - b))/norm\n",
    "\n",
    "def resample_single_stock(single_stock, interval):\n",
    "    df = pd.DataFrame({\n",
    "        'MaxPrice': single_stock['MaxPrice'].resample(interval).max(),\n",
    "        'MinPrice': single_stock['MinPrice'].resample(interval).min(),\n",
    "        'LastEndPrice': single_stock['EndPrice'].resample(interval).last(),\n",
    "        'FirstStartPrice': single_stock['StartPrice'].resample(interval).first(),         \n",
    "        'MeanEndPrice': single_stock['EndPrice'].resample(interval).mean(),        \n",
    "        'HasTrade': single_stock['HasTrade'].resample(interval).max(),\n",
    "        'Mnemonic': single_stock['Mnemonic'].resample(interval).last(),\n",
    "        'Date': single_stock['Date'].resample(interval).last(),        \n",
    "    })\n",
    "    \n",
    "    # Warning: this works because we had forward filled the prices\n",
    "    df = df[df['HasTrade'] == 1.0]\n",
    "    return df\n",
    "\n",
    "def rev_pct_change(a, t):\n",
    "    one_step_in_past = a\n",
    "    t_steps_in_past = a.shift(t).ffill()\n",
    "    return ((one_step_in_past - t_steps_in_past)/one_step_in_past).fillna(0.0)\n",
    "\n",
    "def add_non_linear_features(main, resampled, interval):\n",
    "    main['tmp:SignDirection@' + interval] = np.sign(main['x:Direction@' + interval])\n",
    "\n",
    "    main['tmp:D1@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == 1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == 1.0), 1.0, 0.0)\n",
    "\n",
    "    main['tmp:D2@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == -1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == -1.0), -1.0, 0.0)        \n",
    "\n",
    "    main['x:D@' + interval] = main['tmp:D1@' + interval] + main['tmp:D2@' + interval]\n",
    "\n",
    "    main['x:SignDirection-2@' + interval] = np.sign(\n",
    "        (resampled['LastEndPrice'] - resampled['FirstStartPrice'].shift(2).ffill()\n",
    "    )).fillna(0.0)\n",
    "\n",
    "    main['tmp:D1@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == 1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == -1.0), main['x:SignDirection-2@' + interval], 0.0)\n",
    "\n",
    "    main['tmp:D2@' + interval] = np.where( \n",
    "        (main['tmp:SignDirection@' + interval] == -1.0) &\n",
    "        (main['tmp:SignDirection@' + interval].shift(1) == 1.0), main['x:SignDirection-2@' + interval], 0.0)        \n",
    "\n",
    "    main['x:Da@' + interval] = main['tmp:D1@' + interval] + main['tmp:D2@' + interval]\n",
    "    \n",
    "    main = main.drop(columns=[\n",
    "        'tmp:SignDirection@' + interval,\n",
    "        'tmp:D1@' + interval,\n",
    "        'tmp:D2@' + interval\n",
    "    ])\n",
    "        \n",
    "    return main\n",
    "\n",
    "def prepare_single_stock_multi_intervals(single_stock, predicted_price, main_interval, intervals):\n",
    "        \n",
    "    main = resample_single_stock(single_stock, main_interval)\n",
    "    # we use the same anchor\n",
    "    anchor = main['MeanEndPrice']\n",
    "    future_mean_price = main[predicted_price].shift(-1)\n",
    "    \n",
    "    main['y(Return)'] = (future_mean_price - anchor)/anchor\n",
    "\n",
    "    # do not normalize\n",
    "    main['pseudo_y(SignReturn)'] = np.sign(main['y(Return)'])\n",
    "\n",
    "    # actual return won't be normalized\n",
    "    main['pseudo_y(pctChange)'] = (future_mean_price - anchor)/anchor\n",
    "    \n",
    "    # baseline will be normalized\n",
    "    main['baseline'] = main['pseudo_y(pctChange)'].shift(1).fillna(0.0)    \n",
    "    \n",
    "    all_intervals = [main_interval] + intervals\n",
    "    \n",
    "    for interval in all_intervals:\n",
    "        sub = resample_single_stock(single_stock, interval)\n",
    "        resampled = sub.resample(main_interval).last() \n",
    "\n",
    "        main['x:Direction@' + interval] = \\\n",
    "            2.0*(resampled['LastEndPrice'] - resampled['FirstStartPrice'])/ \\\n",
    "            anchor\n",
    "\n",
    "        if enable_non_linear_features:\n",
    "            main = add_non_linear_features(main, resampled, interval)\n",
    "\n",
    "        main['x:H1@' + interval] = - closer_to_with_normalization(\n",
    "                                                 resampled['LastEndPrice'], \n",
    "                                                 resampled['MaxPrice'], \n",
    "                                                 resampled['MinPrice'],\n",
    "                                                 anchor)    \n",
    "        \n",
    "        main['x:EndToMean@' + interval] = (resampled['LastEndPrice'] - resampled['MeanEndPrice'])/anchor\n",
    "        \n",
    "        main['x:AdjustedPctChange@' + interval] = (resampled['LastEndPrice'] - resampled['MeanEndPrice'])/resampled['MeanEndPrice']\n",
    "        main['x:RevPctChange@' + interval] = rev_pct_change(resampled['LastEndPrice'], 1)\n",
    "    \n",
    "    main = main[main['HasTrade'] == 1.0]\n",
    "    meta = main[['MeanEndPrice', 'HasTrade', 'LastEndPrice']]\n",
    "    main = main.drop(columns = [\n",
    "        'MaxPrice',\n",
    "        'MinPrice',\n",
    "        'LastEndPrice',\n",
    "        'FirstStartPrice',         \n",
    "        'MeanEndPrice',     \n",
    "        'HasTrade'       \n",
    "    ])\n",
    "    return main, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NARemover:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    def transform(self, single_stock):\n",
    "        before = single_stock.shape[0]\n",
    "        single_stock = single_stock.dropna()\n",
    "        after = single_stock.shape[0]\n",
    "        print(\"{}: Dropped {:2.2f} % of records due to NA\".format(self.name, 100.0*(before - after)/(0.0001 + before)))\n",
    "        return single_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable we use for predictions start with `x(`, while the variables that should be predicted start with `y(`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>y(Return)</th>\n",
       "      <th>pseudo_y(SignReturn)</th>\n",
       "      <th>pseudo_y(pctChange)</th>\n",
       "      <th>baseline</th>\n",
       "      <th>x:Direction@20Min</th>\n",
       "      <th>x:D@20Min</th>\n",
       "      <th>x:SignDirection-2@20Min</th>\n",
       "      <th>x:Da@20Min</th>\n",
       "      <th>...</th>\n",
       "      <th>x:AdjustedPctChange@10Min</th>\n",
       "      <th>x:RevPctChange@10Min</th>\n",
       "      <th>x:Direction@15Min</th>\n",
       "      <th>x:D@15Min</th>\n",
       "      <th>x:SignDirection-2@15Min</th>\n",
       "      <th>x:Da@15Min</th>\n",
       "      <th>x:H1@15Min</th>\n",
       "      <th>x:EndToMean@15Min</th>\n",
       "      <th>x:AdjustedPctChange@15Min</th>\n",
       "      <th>x:RevPctChange@15Min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CalcDateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:00:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.318812e-03</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:20:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.826712e-03</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 08:40:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.001336</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.215695e-03</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 09:00:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.002918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.727774e-16</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.001703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-03 09:20:00</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>BMW</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.511621e-04</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date Mnemonic  y(Return)  pseudo_y(SignReturn)  \\\n",
       "CalcDateTime                                                                \n",
       "2017-07-03 08:00:00  2017-07-03      BMW   0.002151                   1.0   \n",
       "2017-07-03 08:20:00  2017-07-03      BMW   0.001739                   1.0   \n",
       "2017-07-03 08:40:00  2017-07-03      BMW  -0.000097                  -1.0   \n",
       "2017-07-03 09:00:00  2017-07-03      BMW  -0.000109                  -1.0   \n",
       "2017-07-03 09:20:00  2017-07-03      BMW   0.000863                   1.0   \n",
       "\n",
       "                     pseudo_y(pctChange)  baseline  x:Direction@20Min  \\\n",
       "CalcDateTime                                                            \n",
       "2017-07-03 08:00:00             0.002151  0.000000           0.000488   \n",
       "2017-07-03 08:20:00             0.001739  0.002151           0.005845   \n",
       "2017-07-03 08:40:00            -0.000097  0.001739           0.002918   \n",
       "2017-07-03 09:00:00            -0.000109 -0.000097          -0.002918   \n",
       "2017-07-03 09:20:00             0.000863 -0.000109           0.001702   \n",
       "\n",
       "                     x:D@20Min  x:SignDirection-2@20Min  x:Da@20Min  \\\n",
       "CalcDateTime                                                          \n",
       "2017-07-03 08:00:00        0.0                      0.0         0.0   \n",
       "2017-07-03 08:20:00        1.0                      0.0         0.0   \n",
       "2017-07-03 08:40:00        1.0                      1.0         0.0   \n",
       "2017-07-03 09:00:00        0.0                      1.0         1.0   \n",
       "2017-07-03 09:20:00        0.0                      1.0         1.0   \n",
       "\n",
       "                             ...           x:AdjustedPctChange@10Min  \\\n",
       "CalcDateTime                 ...                                       \n",
       "2017-07-03 08:00:00          ...                            0.000439   \n",
       "2017-07-03 08:20:00          ...                            0.000379   \n",
       "2017-07-03 08:40:00          ...                            0.000413   \n",
       "2017-07-03 09:00:00          ...                           -0.000012   \n",
       "2017-07-03 09:20:00          ...                           -0.000036   \n",
       "\n",
       "                     x:RevPctChange@10Min  x:Direction@15Min  x:D@15Min  \\\n",
       "CalcDateTime                                                              \n",
       "2017-07-03 08:00:00              0.000000           0.004638        0.0   \n",
       "2017-07-03 08:20:00              0.002919           0.003166        1.0   \n",
       "2017-07-03 08:40:00              0.001336           0.002431        1.0   \n",
       "2017-07-03 09:00:00             -0.001582           0.000000        0.0   \n",
       "2017-07-03 09:20:00              0.000851           0.001946        0.0   \n",
       "\n",
       "                     x:SignDirection-2@15Min  x:Da@15Min    x:H1@15Min  \\\n",
       "CalcDateTime                                                             \n",
       "2017-07-03 08:00:00                      0.0         0.0  2.318812e-03   \n",
       "2017-07-03 08:20:00                      0.0         0.0  1.826712e-03   \n",
       "2017-07-03 08:40:00                      1.0         0.0  1.215695e-03   \n",
       "2017-07-03 09:00:00                      1.0         0.0 -1.727774e-16   \n",
       "2017-07-03 09:20:00                      1.0         0.0  8.511621e-04   \n",
       "\n",
       "                     x:EndToMean@15Min  x:AdjustedPctChange@15Min  \\\n",
       "CalcDateTime                                                        \n",
       "2017-07-03 08:00:00           0.001155                   0.001154   \n",
       "2017-07-03 08:20:00           0.000826                   0.000826   \n",
       "2017-07-03 08:40:00           0.000527                   0.000527   \n",
       "2017-07-03 09:00:00          -0.000041                  -0.000041   \n",
       "2017-07-03 09:20:00           0.000032                   0.000032   \n",
       "\n",
       "                     x:RevPctChange@15Min  \n",
       "CalcDateTime                               \n",
       "2017-07-03 08:00:00              0.000000  \n",
       "2017-07-03 08:20:00              0.001581  \n",
       "2017-07-03 08:40:00              0.000972  \n",
       "2017-07-03 09:00:00             -0.001703  \n",
       "2017-07-03 09:20:00              0.001094  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = df_train[df_train.Mnemonic == 'BMW'].copy()\n",
    "dummy = dummy[dummy.HasTrade == 1.0]\n",
    "main_interval_dummy, intervals_dummy = '20Min', ['5Min', '10Min', '15Min']\n",
    "dummy, meta = prepare_single_stock_multi_intervals(dummy, 'MeanEndPrice', main_interval_dummy, intervals_dummy)\n",
    "dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSet:\n",
    "    def __init__(self, X, y, orig_df):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.baseline = orig_df['baseline'].values\n",
    "        self.original_df = orig_df\n",
    "        \n",
    "class TrainingSetBuilder:\n",
    "    def transform(self, single_stock):\n",
    "        x_features = filter(lambda name: name.startswith('x(') or name.startswith('x:'), list(single_stock.dtypes.index))\n",
    "        X = single_stock[x_features].values\n",
    "        y = single_stock[['pseudo_y(SignReturn)']].values \n",
    "        return TrainingSet(X, y, single_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictions:\n",
    "    def __init__(self, predictions, training_set):\n",
    "\n",
    "        self.predictions = predictions\n",
    "        self.training_set = training_set\n",
    "        \n",
    "    def evaluate(self):\n",
    "        single_feature = 'baseline'\n",
    "        stats_df = pd.DataFrame({\n",
    "                      'predictions': self.predictions[:,0],\n",
    "                      'single_feature_pred': self.training_set.original_df[single_feature].values,\n",
    "                      'pseudo_y(SignReturn)': self.training_set.y[:,0],\n",
    "                      'pseudo_y(pctChange)': self.training_set.original_df['pseudo_y(pctChange)'].values,\n",
    "                      'y(Return)': self.training_set.original_df['y(Return)'].values})\n",
    "        \n",
    "        corr = stats_df. \\\n",
    "            corr()[['predictions', 'single_feature_pred']]. \\\n",
    "            iloc[1:]\n",
    "            \n",
    "        pred_signs = np.sign(stats_df['predictions'])\n",
    "        y_signs = np.sign(stats_df['y(Return)'])\n",
    "        has_answer = np.absolute(pred_signs * y_signs).sum()\n",
    "        correct = np.where(pred_signs * y_signs == 1.0, 1.0, 0.0).sum()\n",
    "        \n",
    "        thresholds = []\n",
    "        accuracy = []\n",
    "        correct_lst = []\n",
    "        errors = []\n",
    "        percent_has_answer = []\n",
    "        abs_has_answer = []\n",
    "        achieved_returns = []\n",
    "\n",
    "        preds = stats_df['predictions']\n",
    "        \n",
    "        for d in range(5, 46, 5):\n",
    "            low = np.percentile(preds, d) \n",
    "            high = np.percentile(preds, 100 - d)\n",
    "            thresholded = np.where(preds > high, 1.0, np.where(preds < low, -1.0, 0.0))\n",
    "            c = np.where(np.sign(thresholded)*np.sign(y_signs) == 1.0, 1.0, 0.0).sum()\n",
    "            e = np.where(np.sign(thresholded)*np.sign(y_signs) == -1.0, 1.0, 0.0).sum()\n",
    "            achieved_ret = (stats_df['pseudo_y(pctChange)']*thresholded).sum()\n",
    "            correct_lst.append(c)\n",
    "            errors.append(e)\n",
    "            accuracy.append(c/(c + e))\n",
    "            percent_has_answer.append(100.0*(c + e)/pred_signs.shape[0])\n",
    "            abs_has_answer.append((c + e))\n",
    "            achieved_returns.append(achieved_ret)\n",
    "            thresholds.append(d)\n",
    "            \n",
    "        at_cutoff = DataFrame({\n",
    "                    'thresholds': thresholds,\n",
    "                    'accuracy': accuracy,\n",
    "                    'percent_with_answer': percent_has_answer,\n",
    "                    'absolute_has_answer': abs_has_answer,\n",
    "                    'achieved_returns': achieved_returns,\n",
    "                    'correct': correct_lst,\n",
    "                    'errors': errors\n",
    "        })\n",
    "        at_cutoff['achieved_norm_returns'] = at_cutoff['achieved_returns']/at_cutoff['absolute_has_answer']\n",
    "        \n",
    "        ret = stats_df['pseudo_y(pctChange)']\n",
    "        rand_feature = np.where(np.random.rand(ret.shape[0]) > 0.5, 1.0, -1.0)    \n",
    "        random_returns = (ret * rand_feature).sum()\n",
    "        always_up_returns = (ret*1.0).sum()\n",
    "        always_down_returns = (ret*-1.0).sum()\n",
    "        omnicient_returns = (np.absolute(ret)).sum()\n",
    "        achieved = (ret * pred_signs).sum()\n",
    "        return {\n",
    "            'corr': corr,\n",
    "            'accuracy_at_cutoff': at_cutoff,\n",
    "            'matches': {\n",
    "                'percent_correct': 100*correct/has_answer,\n",
    "                'percent_has_answer': has_answer/pred_signs.shape[0],\n",
    "                'absolute_with_answer': has_answer,\n",
    "                'size': pred_signs.shape[0]\n",
    "            },\n",
    "            'strategies': {\n",
    "                'omniscient': omnicient_returns,\n",
    "                'random': random_returns,\n",
    "                'always_up': always_up_returns,\n",
    "                'always_down': always_down_returns,\n",
    "                'achieved': achieved,\n",
    "                'num_trials': np.absolute(pred_signs).sum()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "class MLModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, training_set, valid_set = None):\n",
    "        train_X, train_y = training_set.X, training_set.y\n",
    "        \n",
    "        if valid_set is None:\n",
    "            valid_X, valid_y = train_X, train_y\n",
    "        else:\n",
    "            valid_X, valid_y = valid_set.X, valid_set.y\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(10, activation='relu', input_shape =(train_X.shape[1],),\n",
    "                        kernel_regularizer=regularizers.l2(0.1))) \n",
    "        model.add(Dense(5, activation='relu', kernel_regularizer=regularizers.l2(0.1)))        \n",
    "\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        self.model = model            \n",
    "\n",
    "        # fit network\n",
    "        history = model.fit(train_X, train_y, epochs=150, batch_size=2500, validation_data=(valid_X, valid_y), verbose=2, shuffle=True)\n",
    "        # plot history\n",
    "        pyplot.plot(history.history['loss'], label='train')\n",
    "        pyplot.plot(history.history['val_loss'], label='valid')\n",
    "        pyplot.legend()\n",
    "        pyplot.show()\n",
    "        \n",
    "    def transform(self, input_set):\n",
    "        predictions = self.model.predict(input_set.X)\n",
    "        return Predictions(predictions, input_set)\n",
    "    \n",
    "    def fit_transform(self, training_set, valid_set):\n",
    "        self.fit(training_set, valid_set)\n",
    "        return self.transform(training_set), self.transform(valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inverter(m, s, th):\n",
    "    return lambda y: y*s + m\n",
    "\n",
    "def make_transformer(m, s, th):\n",
    "    def transform(fn):\n",
    "        norm = (fn-m)/s\n",
    "        return np.where(norm > th, th, np.where(norm < -th, -th, norm))\n",
    "    return transform\n",
    "\n",
    "def fit_normalize_features(prepared_single_stock):\n",
    "    th = 2.5  \n",
    "    inp = prepared_single_stock.copy()\n",
    "    inverters = {}\n",
    "    transformers = {}\n",
    "    \n",
    "    for f in list(inp.dtypes.index):\n",
    "        if f.startswith('x(') or f.startswith('x:') or f == 'baseline':\n",
    "            fn = inp[f]\n",
    "            s = 0.0000001 + np.std(fn.values)\n",
    "            m = np.mean(fn.values)\n",
    "\n",
    "            inverters[f] = make_inverter(m, s, th)\n",
    "            transformers[f] = make_transformer(m, s, th)\n",
    "            inp[f] = transformers[f](fn)\n",
    "        \n",
    "    return inp, transformers, inverters\n",
    "\n",
    "def normalize_features(prepared_single_stock, transformers):\n",
    "    inp = prepared_single_stock.copy()    \n",
    "    for f in list(inp.dtypes.index):\n",
    "        if f.startswith('x(') or f.startswith('x:') or f == 'baseline':\n",
    "            fn = inp[f]\n",
    "            inp[f] = transformers[f](fn)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIE: Dropped 3.93 % of records due to NA\n",
      "('train', (2740, 38))\n",
      "SIE: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "SIE: Dropped 3.70 % of records due to NA\n",
      "('test', (1693, 38))\n",
      "DBK: Dropped 3.89 % of records due to NA\n",
      "('train', (2741, 38))\n",
      "DBK: Dropped 3.95 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "DBK: Dropped 3.41 % of records due to NA\n",
      "('test', (1698, 38))\n",
      "ALV: Dropped 3.89 % of records due to NA\n",
      "('train', (2741, 38))\n",
      "ALV: Dropped 3.93 % of records due to NA\n",
      "('valid', (220, 38))\n",
      "ALV: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "BAYN: Dropped 3.93 % of records due to NA\n",
      "('train', (2740, 38))\n",
      "BAYN: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "BAYN: Dropped 3.53 % of records due to NA\n",
      "('test', (1696, 38))\n",
      "VOW3: Dropped 3.82 % of records due to NA\n",
      "('train', (2743, 38))\n",
      "VOW3: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "VOW3: Dropped 3.36 % of records due to NA\n",
      "('test', (1699, 38))\n",
      "DAI: Dropped 3.93 % of records due to NA\n",
      "('train', (2741, 38))\n",
      "DAI: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "DAI: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "SAP: Dropped 3.75 % of records due to NA\n",
      "('train', (2745, 38))\n",
      "SAP: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "SAP: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "BAS: Dropped 3.72 % of records due to NA\n",
      "('train', (2746, 38))\n",
      "BAS: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "BAS: Dropped 3.30 % of records due to NA\n",
      "('test', (1700, 38))\n",
      "DTE: Dropped 4.03 % of records due to NA\n",
      "('train', (2737, 38))\n",
      "DTE: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "DTE: Dropped 3.47 % of records due to NA\n",
      "('test', (1697, 38))\n",
      "BMW: Dropped 3.65 % of records due to NA\n",
      "('train', (2748, 38))\n",
      "BMW: Dropped 3.49 % of records due to NA\n",
      "('valid', (221, 38))\n",
      "BMW: Dropped 3.36 % of records due to NA\n",
      "('test', (1699, 38))\n",
      "ADS: Dropped 3.96 % of records due to NA\n",
      "('train', (2739, 38))\n",
      "ADS: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "ADS: Dropped 3.87 % of records due to NA\n",
      "('test', (1690, 38))\n",
      "CBK: Dropped 3.96 % of records due to NA\n",
      "('train', (2739, 38))\n",
      "CBK: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "CBK: Dropped 3.58 % of records due to NA\n",
      "('test', (1695, 38))\n",
      "EOAN: Dropped 3.93 % of records due to NA\n",
      "('train', (2740, 38))\n",
      "EOAN: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "EOAN: Dropped 3.70 % of records due to NA\n",
      "('test', (1693, 38))\n",
      "IFX: Dropped 4.03 % of records due to NA\n",
      "('train', (2737, 38))\n",
      "IFX: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "IFX: Dropped 3.87 % of records due to NA\n",
      "('test', (1690, 38))\n",
      "MUV2: Dropped 3.93 % of records due to NA\n",
      "('train', (2740, 38))\n",
      "MUV2: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "MUV2: Dropped 3.92 % of records due to NA\n",
      "('test', (1689, 38))\n",
      "RWE: Dropped 3.61 % of records due to NA\n",
      "('train', (2749, 38))\n",
      "RWE: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "RWE: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "LHA: Dropped 3.65 % of records due to NA\n",
      "('train', (2748, 38))\n",
      "LHA: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "LHA: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "CON: Dropped 4.07 % of records due to NA\n",
      "('train', (2736, 38))\n",
      "CON: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "CON: Dropped 3.92 % of records due to NA\n",
      "('test', (1689, 38))\n",
      "DPW: Dropped 3.89 % of records due to NA\n",
      "('train', (2741, 38))\n",
      "DPW: Dropped 3.93 % of records due to NA\n",
      "('valid', (220, 38))\n",
      "DPW: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "FRE: Dropped 3.82 % of records due to NA\n",
      "('train', (2743, 38))\n",
      "FRE: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "FRE: Dropped 3.75 % of records due to NA\n",
      "('test', (1692, 38))\n",
      "HEN3: Dropped 3.96 % of records due to NA\n",
      "('train', (2739, 38))\n",
      "HEN3: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "HEN3: Dropped 3.98 % of records due to NA\n",
      "('test', (1688, 38))\n",
      "TKA: Dropped 3.72 % of records due to NA\n",
      "('train', (2746, 38))\n",
      "TKA: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "TKA: Dropped 3.75 % of records due to NA\n",
      "('test', (1692, 38))\n",
      "HEI: Dropped 3.72 % of records due to NA\n",
      "('train', (2746, 38))\n",
      "HEI: Dropped 3.95 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "HEI: Dropped 3.64 % of records due to NA\n",
      "('test', (1694, 38))\n",
      "1COV: Dropped 0.39 % of records due to NA\n",
      "('train', (2841, 38))\n",
      "1COV: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "1COV: Dropped 1.25 % of records due to NA\n",
      "('test', (1736, 38))\n",
      "LINU: Dropped 6.76 % of records due to NA\n",
      "('train', (1393, 38))\n",
      "LINU: Dropped 7.14 % of records due to NA\n",
      "('valid', (78, 38))\n",
      "LINU: Dropped 3.98 % of records due to NA\n",
      "('test', (1688, 38))\n",
      "WDI: Dropped 4.11 % of records due to NA\n",
      "('train', (2733, 38))\n",
      "WDI: Dropped 3.95 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "WDI: Dropped 3.92 % of records due to NA\n",
      "('test', (1689, 38))\n",
      "PSM: Dropped 3.72 % of records due to NA\n",
      "('train', (2746, 38))\n",
      "PSM: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "PSM: Dropped 2.73 % of records due to NA\n",
      "('test', (1710, 38))\n",
      "MRK: Dropped 4.03 % of records due to NA\n",
      "('train', (2737, 38))\n",
      "MRK: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "MRK: Dropped 3.81 % of records due to NA\n",
      "('test', (1691, 38))\n",
      "DB1: Dropped 3.86 % of records due to NA\n",
      "('train', (2742, 38))\n",
      "DB1: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "DB1: Dropped 3.75 % of records due to NA\n",
      "('test', (1692, 38))\n",
      "VNA: Dropped 3.79 % of records due to NA\n",
      "('train', (2744, 38))\n",
      "VNA: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "VNA: Dropped 3.47 % of records due to NA\n",
      "('test', (1697, 38))\n",
      "FME: Dropped 3.86 % of records due to NA\n",
      "('train', (2742, 38))\n",
      "FME: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "FME: Dropped 3.75 % of records due to NA\n",
      "('test', (1692, 38))\n",
      "LIN: Dropped 4.03 % of records due to NA\n",
      "('train', (2737, 38))\n",
      "LIN: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "LIN: Dropped 4.46 % of records due to NA\n",
      "('test', (1672, 38))\n",
      "PAH3: Dropped 1.86 % of records due to NA\n",
      "('train', (2797, 38))\n",
      "PAH3: Dropped 1.75 % of records due to NA\n",
      "('valid', (225, 38))\n",
      "PAH3: Dropped 1.65 % of records due to NA\n",
      "('test', (1729, 38))\n",
      "BEI: Dropped 3.93 % of records due to NA\n",
      "('train', (2740, 38))\n",
      "BEI: Dropped 4.37 % of records due to NA\n",
      "('valid', (219, 38))\n",
      "BEI: Dropped 3.58 % of records due to NA\n",
      "('test', (1695, 38))\n",
      "WAF: Dropped 4.11 % of records due to NA\n",
      "('train', (2733, 38))\n",
      "WAF: Dropped 4.82 % of records due to NA\n",
      "('valid', (217, 38))\n",
      "WAF: Dropped 3.98 % of records due to NA\n",
      "('test', (1688, 38))\n",
      "EVT: Dropped 4.11 % of records due to NA\n",
      "('train', (2733, 38))\n",
      "EVT: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "EVT: Dropped 3.87 % of records due to NA\n",
      "('test', (1690, 38))\n",
      "IGY: Dropped 1.02 % of records due to NA\n",
      "('train', (2823, 38))\n",
      "IGY: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "IGY: Dropped 0.85 % of records due to NA\n",
      "('test', (1743, 38))\n",
      "SDF: Dropped 0.74 % of records due to NA\n",
      "('train', (2831, 38))\n",
      "SDF: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "SDF: Dropped 0.74 % of records due to NA\n",
      "('test', (1745, 38))\n",
      "AIXA: Dropped 4.18 % of records due to NA\n",
      "('train', (2731, 38))\n",
      "AIXA: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "AIXA: Dropped 3.75 % of records due to NA\n",
      "('test', (1692, 38))\n",
      "OSR: Dropped 0.70 % of records due to NA\n",
      "('train', (2832, 38))\n",
      "OSR: Dropped 0.87 % of records due to NA\n",
      "('valid', (227, 38))\n",
      "OSR: Dropped 0.57 % of records due to NA\n",
      "('test', (1748, 38))\n",
      "SNH: Dropped 1.58 % of records due to NA\n",
      "('train', (2807, 38))\n",
      "SNH: Dropped 2.18 % of records due to NA\n",
      "('valid', (224, 38))\n",
      "SNH: Dropped 1.02 % of records due to NA\n",
      "('test', (1740, 38))\n",
      "DLG: Dropped 4.04 % of records due to NA\n",
      "('train', (2735, 38))\n",
      "DLG: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "DLG: Dropped 3.87 % of records due to NA\n",
      "('test', (1690, 38))\n",
      "KGX: Dropped 0.84 % of records due to NA\n",
      "('train', (2828, 38))\n",
      "KGX: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "KGX: Dropped 0.74 % of records due to NA\n",
      "('test', (1745, 38))\n",
      "LXS: Dropped 0.88 % of records due to NA\n",
      "('train', (2827, 38))\n",
      "LXS: Dropped 1.31 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "LXS: Dropped 0.74 % of records due to NA\n",
      "('test', (1745, 38))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWNI: Dropped 0.95 % of records due to NA\n",
      "('train', (2825, 38))\n",
      "DWNI: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "DWNI: Dropped 0.28 % of records due to NA\n",
      "('test', (1753, 38))\n",
      "ZAL: Dropped 0.77 % of records due to NA\n",
      "('train', (2830, 38))\n",
      "ZAL: Dropped 1.32 % of records due to NA\n",
      "('valid', (225, 38))\n",
      "ZAL: Dropped 0.68 % of records due to NA\n",
      "('test', (1746, 38))\n",
      "G1A: Dropped 0.60 % of records due to NA\n",
      "('train', (2835, 38))\n",
      "G1A: Dropped 0.88 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "G1A: Dropped 0.40 % of records due to NA\n",
      "('test', (1751, 38))\n",
      "UN01: Dropped 0.81 % of records due to NA\n",
      "('train', (2829, 38))\n",
      "UN01: Dropped 1.31 % of records due to NA\n",
      "('valid', (226, 38))\n",
      "UN01: Dropped 0.68 % of records due to NA\n",
      "('test', (1746, 38))\n",
      "BOSS: Dropped 0.74 % of records due to NA\n",
      "('train', (2831, 38))\n",
      "BOSS: Dropped 0.44 % of records due to NA\n",
      "('valid', (228, 38))\n",
      "BOSS: Dropped 0.85 % of records due to NA\n",
      "('test', (1743, 38))\n",
      "UTDI: Dropped 4.14 % of records due to NA\n",
      "('train', (2732, 38))\n",
      "UTDI: Dropped 4.39 % of records due to NA\n",
      "('valid', (218, 38))\n",
      "UTDI: Dropped 3.98 % of records due to NA\n",
      "('test', (1688, 38))\n",
      "(136779, 38) (10878, 38) (85302, 38)\n"
     ]
    }
   ],
   "source": [
    "combined_training_set = []\n",
    "combined_valid_set = []\n",
    "combined_test_set = []\n",
    "\n",
    "main_interval, intervals = '20Min', ['5Min', '10Min', '15Min']\n",
    "#main_interval, intervals = '4H', ['30Min', '1H', '2H']\n",
    "\n",
    "normalizers = {}\n",
    "\n",
    "for mnemonic in most_liquid_stocks:\n",
    "    single_stock = df_train[df_train.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0]\n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock, single_stock_transformer, _ = fit_normalize_features(single_stock)\n",
    "    normalizers[mnemonic] = single_stock_transformer\n",
    "    \n",
    "    combined_training_set.append(single_stock)\n",
    "    print(\"train\", single_stock.shape)\n",
    "    \n",
    "    single_stock = df_valid[df_valid.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0] \n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock = normalize_features(single_stock, normalizers[mnemonic])\n",
    "    \n",
    "    combined_valid_set.append(single_stock)\n",
    "    print(\"valid\", single_stock.shape)    \n",
    "    \n",
    "    single_stock = df_test[df_test.Mnemonic == mnemonic].copy()\n",
    "    single_stock = single_stock[single_stock.HasTrade == 1.0] \n",
    "    single_stock, meta = prepare_single_stock_multi_intervals(single_stock, 'MeanEndPrice', main_interval, intervals)\n",
    "    single_stock = NARemover(mnemonic).transform(single_stock)\n",
    "    single_stock = normalize_features(single_stock, normalizers[mnemonic])\n",
    "    combined_test_set.append(single_stock)\n",
    "    print(\"test\", single_stock.shape) \n",
    "    \n",
    "combined_training_set_df = pd.concat(combined_training_set, axis=0)\n",
    "training_set = TrainingSetBuilder().transform(combined_training_set_df)\n",
    "    \n",
    "combined_valid_set_df = pd.concat(combined_valid_set, axis=0)\n",
    "valid_set = TrainingSetBuilder().transform(combined_valid_set_df) \n",
    "\n",
    "combined_test_set_df = pd.concat(combined_test_set, axis=0)\n",
    "test_set = TrainingSetBuilder().transform(combined_test_set_df) \n",
    "    \n",
    "print training_set.original_df.shape, valid_set.original_df.shape,  test_set.original_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "class LinearModel:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    def fit(self, training_set, valid_set = None):\n",
    "        train_X, train_y = training_set.X[:,:], training_set.y\n",
    "        \n",
    "        if valid_set is None:\n",
    "            valid_X, valid_y = train_X, train_y\n",
    "        else:\n",
    "            valid_X, valid_y = valid_set.X, valid_set.y\n",
    "            \n",
    "        self.model = Ridge(alpha=1.5)\n",
    "        # train_y should be -1/+1\n",
    "        self.model.fit(train_X, train_y)\n",
    "       \n",
    "\n",
    "    def transform(self, input_set):\n",
    "        return Predictions(self.model.predict(input_set.X), input_set)\n",
    "    \n",
    "    def fit_transform(self, training_set, valid_set):\n",
    "        self.fit(training_set, valid_set)\n",
    "        return self.transform(training_set), self.transform(valid_set)    \n",
    "\n",
    "model = LinearModel()\n",
    "train_predictions, valid_predictions = model.fit_transform(training_set, valid_set)\n",
    "print \"fitted model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 136685.0,\n",
       " 'percent_correct': 78.58140981087902,\n",
       " 'percent_has_answer': 0.9993127599997076,\n",
       " 'size': 136779}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 10871.0,\n",
       " 'percent_correct': 77.92291417532886,\n",
       " 'percent_has_answer': 0.9993564993564994,\n",
       " 'size': 10878}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'absolute_with_answer': 85247.0,\n",
       " 'percent_correct': 78.82858047790538,\n",
       " 'percent_has_answer': 0.9993552319992497,\n",
       " 'size': 85302}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.transform(test_set)\n",
    "test_predictions.evaluate()['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13675.0</td>\n",
       "      <td>0.967898</td>\n",
       "      <td>48.329695</td>\n",
       "      <td>13236.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>9.997880</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27351.0</td>\n",
       "      <td>0.954408</td>\n",
       "      <td>73.373413</td>\n",
       "      <td>26104.0</td>\n",
       "      <td>1247.0</td>\n",
       "      <td>19.996491</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41027.0</td>\n",
       "      <td>0.938675</td>\n",
       "      <td>91.624222</td>\n",
       "      <td>38511.0</td>\n",
       "      <td>2516.0</td>\n",
       "      <td>29.995102</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54701.0</td>\n",
       "      <td>0.920312</td>\n",
       "      <td>105.179385</td>\n",
       "      <td>50342.0</td>\n",
       "      <td>4359.0</td>\n",
       "      <td>39.992250</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68375.0</td>\n",
       "      <td>0.901265</td>\n",
       "      <td>116.965169</td>\n",
       "      <td>61624.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>49.989399</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>82044.0</td>\n",
       "      <td>0.880686</td>\n",
       "      <td>125.994906</td>\n",
       "      <td>72255.0</td>\n",
       "      <td>9789.0</td>\n",
       "      <td>59.982892</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>95716.0</td>\n",
       "      <td>0.859198</td>\n",
       "      <td>132.340416</td>\n",
       "      <td>82239.0</td>\n",
       "      <td>13477.0</td>\n",
       "      <td>69.978579</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>109383.0</td>\n",
       "      <td>0.836812</td>\n",
       "      <td>137.513070</td>\n",
       "      <td>91533.0</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>79.970610</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123037.0</td>\n",
       "      <td>0.812081</td>\n",
       "      <td>140.439463</td>\n",
       "      <td>99916.0</td>\n",
       "      <td>23121.0</td>\n",
       "      <td>89.953136</td>\n",
       "      <td>45</td>\n",
       "      <td>0.001141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0              13675.0  0.967898         48.329695  13236.0    439.0   \n",
       "1              27351.0  0.954408         73.373413  26104.0   1247.0   \n",
       "2              41027.0  0.938675         91.624222  38511.0   2516.0   \n",
       "3              54701.0  0.920312        105.179385  50342.0   4359.0   \n",
       "4              68375.0  0.901265        116.965169  61624.0   6751.0   \n",
       "5              82044.0  0.880686        125.994906  72255.0   9789.0   \n",
       "6              95716.0  0.859198        132.340416  82239.0  13477.0   \n",
       "7             109383.0  0.836812        137.513070  91533.0  17850.0   \n",
       "8             123037.0  0.812081        140.439463  99916.0  23121.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.997880           5               0.003534  \n",
       "1            19.996491          10               0.002683  \n",
       "2            29.995102          15               0.002233  \n",
       "3            39.992250          20               0.001923  \n",
       "4            49.989399          25               0.001711  \n",
       "5            59.982892          30               0.001536  \n",
       "6            69.978579          35               0.001383  \n",
       "7            79.970610          40               0.001257  \n",
       "8            89.953136          45               0.001141  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So if you play 136779 times on the Training Set with 1 EUR and you always guess the movement,\n",
      "ignoring all transactions cost, you will make 193.979672637. \n",
      "Instead you make 141.158087695 or 72.7695256806 percent of the ideally achievable.\n",
      "If you use the baseline you will make 42.8868770265 or 22.1089542236 percent of ideal\n"
     ]
    }
   ],
   "source": [
    "def pred_baseline(d):\n",
    "    single_feature = 'baseline'\n",
    "    preds = d.training_set.original_df[single_feature].values\n",
    "    preds = preds.reshape((preds.shape[0], 1))\n",
    "    return Predictions(preds, d.training_set).evaluate()\n",
    "\n",
    "def readable_summary(which_set, p):\n",
    "    achieved = p.evaluate()['strategies']['achieved']\n",
    "    achieved_baseline = pred_baseline(p)['strategies']['achieved']\n",
    "    per_change = np.mean(np.absolute(p.training_set.original_df['pseudo_y(pctChange)']))\n",
    "    n = p.training_set.original_df.shape[0]\n",
    "    print (\"\"\"So if you play {} times on the {} with 1 EUR and you always guess the movement,\n",
    "ignoring all transactions cost, you will make {}. \n",
    "Instead you make {} or {} percent of the ideally achievable.\n",
    "If you use the baseline you will make {} or {} percent of ideal\"\"\".format(\n",
    "        n, which_set, n * per_change, achieved, 100.0*achieved/(n*per_change),\n",
    "          achieved_baseline, 100.0*achieved_baseline/(n*per_change)))\n",
    "readable_summary('Training Set', train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 141.15808769512572,\n",
       " 'always_down': -0.22715238132307247,\n",
       " 'always_up': 0.22715238132307247,\n",
       " 'num_trials': 136779.0,\n",
       " 'omniscient': 193.97967263745477,\n",
       " 'random': -1.5135996165857062}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions.evaluate()['strategies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 3.435967184336051,\n",
       " 'always_down': -1.0287977152997019,\n",
       " 'always_up': 1.0287977152997019,\n",
       " 'num_trials': 10878.0,\n",
       " 'omniscient': 17.992567078043844,\n",
       " 'random': -0.19091830333221688}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_baseline(valid_predictions)['strategies'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1088.0</td>\n",
       "      <td>0.962316</td>\n",
       "      <td>3.119699</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>10.001839</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2176.0</td>\n",
       "      <td>0.948070</td>\n",
       "      <td>4.775376</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>20.003677</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3264.0</td>\n",
       "      <td>0.933517</td>\n",
       "      <td>5.774539</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>30.005516</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4352.0</td>\n",
       "      <td>0.914982</td>\n",
       "      <td>6.476276</td>\n",
       "      <td>3982.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>40.007354</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5440.0</td>\n",
       "      <td>0.897978</td>\n",
       "      <td>7.494586</td>\n",
       "      <td>4885.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>50.009193</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6528.0</td>\n",
       "      <td>0.879902</td>\n",
       "      <td>8.253540</td>\n",
       "      <td>5744.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>60.011031</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7614.0</td>\n",
       "      <td>0.858025</td>\n",
       "      <td>9.649029</td>\n",
       "      <td>6533.0</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>69.994484</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8700.0</td>\n",
       "      <td>0.832874</td>\n",
       "      <td>10.029113</td>\n",
       "      <td>7246.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>79.977937</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9785.0</td>\n",
       "      <td>0.809198</td>\n",
       "      <td>9.594364</td>\n",
       "      <td>7918.0</td>\n",
       "      <td>1867.0</td>\n",
       "      <td>89.952197</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct  errors  \\\n",
       "0               1088.0  0.962316          3.119699   1047.0    41.0   \n",
       "1               2176.0  0.948070          4.775376   2063.0   113.0   \n",
       "2               3264.0  0.933517          5.774539   3047.0   217.0   \n",
       "3               4352.0  0.914982          6.476276   3982.0   370.0   \n",
       "4               5440.0  0.897978          7.494586   4885.0   555.0   \n",
       "5               6528.0  0.879902          8.253540   5744.0   784.0   \n",
       "6               7614.0  0.858025          9.649029   6533.0  1081.0   \n",
       "7               8700.0  0.832874         10.029113   7246.0  1454.0   \n",
       "8               9785.0  0.809198          9.594364   7918.0  1867.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0            10.001839           5               0.002867  \n",
       "1            20.003677          10               0.002195  \n",
       "2            30.005516          15               0.001769  \n",
       "3            40.007354          20               0.001488  \n",
       "4            50.009193          25               0.001378  \n",
       "5            60.011031          30               0.001264  \n",
       "6            69.994484          35               0.001267  \n",
       "7            79.977937          40               0.001153  \n",
       "8            89.952197          45               0.000981  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline on Testset: Accuracy at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8526.0</td>\n",
       "      <td>0.635820</td>\n",
       "      <td>8.610007</td>\n",
       "      <td>5421.0</td>\n",
       "      <td>3105.0</td>\n",
       "      <td>9.995076</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17053.0</td>\n",
       "      <td>0.632851</td>\n",
       "      <td>15.213155</td>\n",
       "      <td>10792.0</td>\n",
       "      <td>6261.0</td>\n",
       "      <td>19.991325</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25577.0</td>\n",
       "      <td>0.623099</td>\n",
       "      <td>20.370863</td>\n",
       "      <td>15937.0</td>\n",
       "      <td>9640.0</td>\n",
       "      <td>29.984057</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34106.0</td>\n",
       "      <td>0.615962</td>\n",
       "      <td>24.836214</td>\n",
       "      <td>21008.0</td>\n",
       "      <td>13098.0</td>\n",
       "      <td>39.982650</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42630.0</td>\n",
       "      <td>0.607108</td>\n",
       "      <td>28.144498</td>\n",
       "      <td>25881.0</td>\n",
       "      <td>16749.0</td>\n",
       "      <td>49.975382</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51154.0</td>\n",
       "      <td>0.599054</td>\n",
       "      <td>30.643016</td>\n",
       "      <td>30644.0</td>\n",
       "      <td>20510.0</td>\n",
       "      <td>59.968113</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59677.0</td>\n",
       "      <td>0.591736</td>\n",
       "      <td>32.790155</td>\n",
       "      <td>35313.0</td>\n",
       "      <td>24364.0</td>\n",
       "      <td>69.959673</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68203.0</td>\n",
       "      <td>0.583772</td>\n",
       "      <td>34.640306</td>\n",
       "      <td>39815.0</td>\n",
       "      <td>28388.0</td>\n",
       "      <td>79.954749</td>\n",
       "      <td>40</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76727.0</td>\n",
       "      <td>0.577502</td>\n",
       "      <td>35.665803</td>\n",
       "      <td>44310.0</td>\n",
       "      <td>32417.0</td>\n",
       "      <td>89.947481</td>\n",
       "      <td>45</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0               8526.0  0.635820          8.610007   5421.0   3105.0   \n",
       "1              17053.0  0.632851         15.213155  10792.0   6261.0   \n",
       "2              25577.0  0.623099         20.370863  15937.0   9640.0   \n",
       "3              34106.0  0.615962         24.836214  21008.0  13098.0   \n",
       "4              42630.0  0.607108         28.144498  25881.0  16749.0   \n",
       "5              51154.0  0.599054         30.643016  30644.0  20510.0   \n",
       "6              59677.0  0.591736         32.790155  35313.0  24364.0   \n",
       "7              68203.0  0.583772         34.640306  39815.0  28388.0   \n",
       "8              76727.0  0.577502         35.665803  44310.0  32417.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.995076           5               0.001010  \n",
       "1            19.991325          10               0.000892  \n",
       "2            29.984057          15               0.000796  \n",
       "3            39.982650          20               0.000728  \n",
       "4            49.975382          25               0.000660  \n",
       "5            59.968113          30               0.000599  \n",
       "6            69.959673          35               0.000549  \n",
       "7            79.954749          40               0.000508  \n",
       "8            89.947481          45               0.000465  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the baseline\n",
    "pred_baseline(test_predictions)['accuracy_at_cutoff'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline on Testset: Comparison of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 36.311282975112185,\n",
       " 'always_down': 5.455562058722664,\n",
       " 'always_up': -5.455562058722664,\n",
       " 'num_trials': 85302.0,\n",
       " 'omniscient': 152.78525602638533,\n",
       " 'random': 0.9115976501378398}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for the baseline\n",
    "pred_baseline(test_predictions)['strategies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model on Testset: Accuracy at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_has_answer</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>achieved_returns</th>\n",
       "      <th>correct</th>\n",
       "      <th>errors</th>\n",
       "      <th>percent_with_answer</th>\n",
       "      <th>thresholds</th>\n",
       "      <th>achieved_norm_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8530.0</td>\n",
       "      <td>0.966940</td>\n",
       "      <td>34.105227</td>\n",
       "      <td>8248.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>9.999766</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17060.0</td>\n",
       "      <td>0.952345</td>\n",
       "      <td>54.518566</td>\n",
       "      <td>16247.0</td>\n",
       "      <td>813.0</td>\n",
       "      <td>19.999531</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25586.0</td>\n",
       "      <td>0.937466</td>\n",
       "      <td>70.214720</td>\n",
       "      <td>23986.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>29.994607</td>\n",
       "      <td>15</td>\n",
       "      <td>0.002744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34110.0</td>\n",
       "      <td>0.922281</td>\n",
       "      <td>83.392535</td>\n",
       "      <td>31459.0</td>\n",
       "      <td>2651.0</td>\n",
       "      <td>39.987339</td>\n",
       "      <td>20</td>\n",
       "      <td>0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42636.0</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>93.231875</td>\n",
       "      <td>38608.0</td>\n",
       "      <td>4028.0</td>\n",
       "      <td>49.982415</td>\n",
       "      <td>25</td>\n",
       "      <td>0.002187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51164.0</td>\n",
       "      <td>0.884900</td>\n",
       "      <td>100.804528</td>\n",
       "      <td>45275.0</td>\n",
       "      <td>5889.0</td>\n",
       "      <td>59.979836</td>\n",
       "      <td>30</td>\n",
       "      <td>0.001970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59687.0</td>\n",
       "      <td>0.864393</td>\n",
       "      <td>106.519504</td>\n",
       "      <td>51593.0</td>\n",
       "      <td>8094.0</td>\n",
       "      <td>69.971396</td>\n",
       "      <td>35</td>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68210.0</td>\n",
       "      <td>0.841636</td>\n",
       "      <td>110.613616</td>\n",
       "      <td>57408.0</td>\n",
       "      <td>10802.0</td>\n",
       "      <td>79.962955</td>\n",
       "      <td>40</td>\n",
       "      <td>0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>76726.0</td>\n",
       "      <td>0.816164</td>\n",
       "      <td>112.662359</td>\n",
       "      <td>62621.0</td>\n",
       "      <td>14105.0</td>\n",
       "      <td>89.946308</td>\n",
       "      <td>45</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_has_answer  accuracy  achieved_returns  correct   errors  \\\n",
       "0               8530.0  0.966940         34.105227   8248.0    282.0   \n",
       "1              17060.0  0.952345         54.518566  16247.0    813.0   \n",
       "2              25586.0  0.937466         70.214720  23986.0   1600.0   \n",
       "3              34110.0  0.922281         83.392535  31459.0   2651.0   \n",
       "4              42636.0  0.905526         93.231875  38608.0   4028.0   \n",
       "5              51164.0  0.884900        100.804528  45275.0   5889.0   \n",
       "6              59687.0  0.864393        106.519504  51593.0   8094.0   \n",
       "7              68210.0  0.841636        110.613616  57408.0  10802.0   \n",
       "8              76726.0  0.816164        112.662359  62621.0  14105.0   \n",
       "\n",
       "   percent_with_answer  thresholds  achieved_norm_returns  \n",
       "0             9.999766           5               0.003998  \n",
       "1            19.999531          10               0.003196  \n",
       "2            29.994607          15               0.002744  \n",
       "3            39.987339          20               0.002445  \n",
       "4            49.982415          25               0.002187  \n",
       "5            59.979836          30               0.001970  \n",
       "6            69.971396          35               0.001785  \n",
       "7            79.962955          40               0.001622  \n",
       "8            89.946308          45               0.001468  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is for ML\n",
    "test_predictions.evaluate()['accuracy_at_cutoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model on Testset: Comparison of Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'achieved': 113.65066973820483,\n",
       " 'always_down': 5.455562058722664,\n",
       " 'always_up': -5.455562058722664,\n",
       " 'num_trials': 85302.0,\n",
       " 'omniscient': 152.78525602638533,\n",
       " 'random': 0.3321146596207882}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for ML\n",
    "Predictions(test_predictions.predictions, test_predictions.training_set).evaluate()['strategies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So if you play 85302 times on the Test set with 1 EUR and you always guess the movement,\n",
      "ignoring all transactions cost, you will make 152.785256026. \n",
      "Instead you make 113.650669738 or 74.3858882028 percent of the ideally achievable.\n",
      "If you use the baseline you will make 36.3112829751 or 23.7662218983 percent of ideal\n"
     ]
    }
   ],
   "source": [
    "readable_summary('Test set', test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by Mnemonic and by Date\n",
    "\n",
    "It is known that when it comes to stock predictions, different stocks and different days will exibit different performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_by(grouping_feature, predictions):\n",
    "    df = predictions.training_set.original_df\n",
    "    s = df[['Date', 'Mnemonic', 'pseudo_y(SignReturn)']].copy()\n",
    "    s['Predictions'] = predictions.predictions\n",
    "    s['Baseline'] = df['baseline']\n",
    "\n",
    "    def agg(group):\n",
    "        pred = group['Predictions']\n",
    "        baseline = group['Baseline']\n",
    "        rets = group['pseudo_y(SignReturn)']\n",
    "        c = pred.corr(rets)\n",
    "        c = np.where(np.sign(pred)*np.sign(rets) == 1.0, 1.0, 0.0).sum()\n",
    "        e = np.where(np.sign(pred)*np.sign(rets) == -1.0, 1.0, 0.0).sum()\n",
    "        acc = c/(c + e)\n",
    "\n",
    "        c_baseline = np.where(np.sign(baseline)*np.sign(rets) == 1.0, 1.0, 0.0).sum()\n",
    "        e_baseline = np.where(np.sign(baseline)*np.sign(rets) == -1.0, 1.0, 0.0).sum()\n",
    "        acc_baseline = c_baseline/(c_baseline + e_baseline)\n",
    "\n",
    "        l = group.shape[0]\n",
    "        return {\"corr\": c, 'size': l, 'accuracy': acc, 'acc_baseline': acc_baseline}\n",
    "    f = s.groupby(grouping_feature).apply(agg).to_frame(\"agg\")\n",
    "\n",
    "    f['AccuracyPred'] = f['agg'].map(lambda i: i['accuracy'])\n",
    "    f['AccuracyBaseline'] = f['agg'].map(lambda i: i['acc_baseline'])\n",
    "    f['AccPred - AccBaseline'] = f['AccuracyPred'] - f['AccuracyBaseline']\n",
    "    f = f.drop(columns=['agg'])\n",
    "\n",
    "    f = f[f.index != '2017-10-14'] # remove this date which has one data point\n",
    "    f[['AccuracyPred', 'AccuracyBaseline']].plot()\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ce9988b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = plot_accuracy_by('Mnemonic', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CON</th>\n",
       "      <td>0.814683</td>\n",
       "      <td>0.544109</td>\n",
       "      <td>0.270574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAS</th>\n",
       "      <td>0.811065</td>\n",
       "      <td>0.570924</td>\n",
       "      <td>0.240141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIE</th>\n",
       "      <td>0.810763</td>\n",
       "      <td>0.564755</td>\n",
       "      <td>0.246008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNA</th>\n",
       "      <td>0.810731</td>\n",
       "      <td>0.571934</td>\n",
       "      <td>0.238797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RWE</th>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.588548</td>\n",
       "      <td>0.221370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADS</th>\n",
       "      <td>0.804618</td>\n",
       "      <td>0.591474</td>\n",
       "      <td>0.213144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1COV</th>\n",
       "      <td>0.803458</td>\n",
       "      <td>0.592507</td>\n",
       "      <td>0.210951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTE</th>\n",
       "      <td>0.801063</td>\n",
       "      <td>0.560803</td>\n",
       "      <td>0.240260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBK</th>\n",
       "      <td>0.800353</td>\n",
       "      <td>0.568316</td>\n",
       "      <td>0.232038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DB1</th>\n",
       "      <td>0.800236</td>\n",
       "      <td>0.557920</td>\n",
       "      <td>0.242317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOW3</th>\n",
       "      <td>0.799057</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.225103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRK</th>\n",
       "      <td>0.798817</td>\n",
       "      <td>0.591716</td>\n",
       "      <td>0.207101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.562906</td>\n",
       "      <td>0.234495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLG</th>\n",
       "      <td>0.795737</td>\n",
       "      <td>0.556542</td>\n",
       "      <td>0.239195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FME</th>\n",
       "      <td>0.794917</td>\n",
       "      <td>0.579196</td>\n",
       "      <td>0.215721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBK</th>\n",
       "      <td>0.794448</td>\n",
       "      <td>0.565269</td>\n",
       "      <td>0.229179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW</th>\n",
       "      <td>0.793996</td>\n",
       "      <td>0.576221</td>\n",
       "      <td>0.217775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIXA</th>\n",
       "      <td>0.793735</td>\n",
       "      <td>0.582742</td>\n",
       "      <td>0.210993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAYN</th>\n",
       "      <td>0.793042</td>\n",
       "      <td>0.556014</td>\n",
       "      <td>0.237028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEN3</th>\n",
       "      <td>0.793001</td>\n",
       "      <td>0.582444</td>\n",
       "      <td>0.210558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Mnemonic                                                       \n",
       "CON           0.814683          0.544109               0.270574\n",
       "BAS           0.811065          0.570924               0.240141\n",
       "SIE           0.810763          0.564755               0.246008\n",
       "VNA           0.810731          0.571934               0.238797\n",
       "RWE           0.809917          0.588548               0.221370\n",
       "ADS           0.804618          0.591474               0.213144\n",
       "1COV          0.803458          0.592507               0.210951\n",
       "DTE           0.801063          0.560803               0.240260\n",
       "DBK           0.800353          0.568316               0.232038\n",
       "DB1           0.800236          0.557920               0.242317\n",
       "VOW3          0.799057          0.573954               0.225103\n",
       "MRK           0.798817          0.591716               0.207101\n",
       "SAP           0.797401          0.562906               0.234495\n",
       "DLG           0.795737          0.556542               0.239195\n",
       "FME           0.794917          0.579196               0.215721\n",
       "CBK           0.794448          0.565269               0.229179\n",
       "BMW           0.793996          0.576221               0.217775\n",
       "AIXA          0.793735          0.582742               0.210993\n",
       "BAYN          0.793042          0.556014               0.237028\n",
       "HEN3          0.793001          0.582444               0.210558"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mnemonic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDF</th>\n",
       "      <td>0.786001</td>\n",
       "      <td>0.579461</td>\n",
       "      <td>0.206540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSR</th>\n",
       "      <td>0.785919</td>\n",
       "      <td>0.567258</td>\n",
       "      <td>0.218661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DWNI</th>\n",
       "      <td>0.785388</td>\n",
       "      <td>0.571918</td>\n",
       "      <td>0.213470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEI</th>\n",
       "      <td>0.784534</td>\n",
       "      <td>0.580283</td>\n",
       "      <td>0.204250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LXS</th>\n",
       "      <td>0.784404</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.215596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUV2</th>\n",
       "      <td>0.783175</td>\n",
       "      <td>0.549171</td>\n",
       "      <td>0.234005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FRE</th>\n",
       "      <td>0.781657</td>\n",
       "      <td>0.579290</td>\n",
       "      <td>0.202367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSM</th>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.579532</td>\n",
       "      <td>0.201170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPW</th>\n",
       "      <td>0.778829</td>\n",
       "      <td>0.576582</td>\n",
       "      <td>0.202247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOSS</th>\n",
       "      <td>0.775545</td>\n",
       "      <td>0.568312</td>\n",
       "      <td>0.207233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZAL</th>\n",
       "      <td>0.774341</td>\n",
       "      <td>0.569874</td>\n",
       "      <td>0.204467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALV</th>\n",
       "      <td>0.773908</td>\n",
       "      <td>0.561393</td>\n",
       "      <td>0.212515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BEI</th>\n",
       "      <td>0.773318</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.186541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UTDI</th>\n",
       "      <td>0.771919</td>\n",
       "      <td>0.571090</td>\n",
       "      <td>0.200829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFX</th>\n",
       "      <td>0.771649</td>\n",
       "      <td>0.573547</td>\n",
       "      <td>0.198102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1A</th>\n",
       "      <td>0.766286</td>\n",
       "      <td>0.558857</td>\n",
       "      <td>0.207429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVT</th>\n",
       "      <td>0.760947</td>\n",
       "      <td>0.565680</td>\n",
       "      <td>0.195266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIN</th>\n",
       "      <td>0.758683</td>\n",
       "      <td>0.554491</td>\n",
       "      <td>0.204192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UN01</th>\n",
       "      <td>0.758185</td>\n",
       "      <td>0.567490</td>\n",
       "      <td>0.190695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IGY</th>\n",
       "      <td>0.751867</td>\n",
       "      <td>0.566916</td>\n",
       "      <td>0.184951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Mnemonic                                                       \n",
       "SDF           0.786001          0.579461               0.206540\n",
       "OSR           0.785919          0.567258               0.218661\n",
       "DWNI          0.785388          0.571918               0.213470\n",
       "HEI           0.784534          0.580283               0.204250\n",
       "LXS           0.784404          0.568807               0.215596\n",
       "MUV2          0.783175          0.549171               0.234005\n",
       "FRE           0.781657          0.579290               0.202367\n",
       "PSM           0.780702          0.579532               0.201170\n",
       "DPW           0.778829          0.576582               0.202247\n",
       "BOSS          0.775545          0.568312               0.207233\n",
       "ZAL           0.774341          0.569874               0.204467\n",
       "ALV           0.773908          0.561393               0.212515\n",
       "BEI           0.773318          0.586777               0.186541\n",
       "UTDI          0.771919          0.571090               0.200829\n",
       "IFX           0.771649          0.573547               0.198102\n",
       "G1A           0.766286          0.558857               0.207429\n",
       "EVT           0.760947          0.565680               0.195266\n",
       "LIN           0.758683          0.554491               0.204192\n",
       "UN01          0.758185          0.567490               0.190695\n",
       "IGY           0.751867          0.566916               0.184951"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ce9968390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perf = plot_accuracy_by('Date', test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>0.832937</td>\n",
       "      <td>0.608076</td>\n",
       "      <td>0.224861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-05</th>\n",
       "      <td>0.829249</td>\n",
       "      <td>0.598419</td>\n",
       "      <td>0.230830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.559684</td>\n",
       "      <td>0.266403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>0.818263</td>\n",
       "      <td>0.602507</td>\n",
       "      <td>0.215756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-25</th>\n",
       "      <td>0.817117</td>\n",
       "      <td>0.635135</td>\n",
       "      <td>0.181982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-20</th>\n",
       "      <td>0.816019</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>0.266455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.541270</td>\n",
       "      <td>0.274603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-12</th>\n",
       "      <td>0.814138</td>\n",
       "      <td>0.533757</td>\n",
       "      <td>0.280381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-07</th>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.515079</td>\n",
       "      <td>0.298413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-11</th>\n",
       "      <td>0.813406</td>\n",
       "      <td>0.591486</td>\n",
       "      <td>0.221920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-27</th>\n",
       "      <td>0.812054</td>\n",
       "      <td>0.566217</td>\n",
       "      <td>0.245837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>0.811709</td>\n",
       "      <td>0.561709</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-25</th>\n",
       "      <td>0.807296</td>\n",
       "      <td>0.554322</td>\n",
       "      <td>0.252974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.620143</td>\n",
       "      <td>0.183981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-30</th>\n",
       "      <td>0.803628</td>\n",
       "      <td>0.544164</td>\n",
       "      <td>0.259464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-26</th>\n",
       "      <td>0.803411</td>\n",
       "      <td>0.539497</td>\n",
       "      <td>0.263914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-16</th>\n",
       "      <td>0.802059</td>\n",
       "      <td>0.612827</td>\n",
       "      <td>0.189232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-22</th>\n",
       "      <td>0.800475</td>\n",
       "      <td>0.560570</td>\n",
       "      <td>0.239905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>0.800317</td>\n",
       "      <td>0.599049</td>\n",
       "      <td>0.201268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-23</th>\n",
       "      <td>0.800159</td>\n",
       "      <td>0.596352</td>\n",
       "      <td>0.203807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Date                                                             \n",
       "2018-02-08      0.832937          0.608076               0.224861\n",
       "2018-03-05      0.829249          0.598419               0.230830\n",
       "2018-02-07      0.826087          0.559684               0.266403\n",
       "2018-03-26      0.818263          0.602507               0.215756\n",
       "2018-04-25      0.817117          0.635135               0.181982\n",
       "2018-02-20      0.816019          0.549564               0.266455\n",
       "2018-02-12      0.815873          0.541270               0.274603\n",
       "2018-03-12      0.814138          0.533757               0.280381\n",
       "2018-03-07      0.813492          0.515079               0.298413\n",
       "2018-04-11      0.813406          0.591486               0.221920\n",
       "2018-02-27      0.812054          0.566217               0.245837\n",
       "2018-01-22      0.811709          0.561709               0.250000\n",
       "2018-01-25      0.807296          0.554322               0.252974\n",
       "2018-02-16      0.804124          0.620143               0.183981\n",
       "2018-01-30      0.803628          0.544164               0.259464\n",
       "2018-04-26      0.803411          0.539497               0.263914\n",
       "2018-01-16      0.802059          0.612827               0.189232\n",
       "2018-02-22      0.800475          0.560570               0.239905\n",
       "2018-02-15      0.800317          0.599049               0.201268\n",
       "2018-01-23      0.800159          0.596352               0.203807"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccuracyPred</th>\n",
       "      <th>AccuracyBaseline</th>\n",
       "      <th>AccPred - AccBaseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>0.773123</td>\n",
       "      <td>0.566008</td>\n",
       "      <td>0.207115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-18</th>\n",
       "      <td>0.772691</td>\n",
       "      <td>0.546172</td>\n",
       "      <td>0.226519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12</th>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.558268</td>\n",
       "      <td>0.213386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>0.771610</td>\n",
       "      <td>0.574941</td>\n",
       "      <td>0.196669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-09</th>\n",
       "      <td>0.771610</td>\n",
       "      <td>0.553529</td>\n",
       "      <td>0.218081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-17</th>\n",
       "      <td>0.771377</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.207021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-24</th>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.579970</td>\n",
       "      <td>0.191330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>0.770635</td>\n",
       "      <td>0.546825</td>\n",
       "      <td>0.223810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>0.770324</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.211523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-19</th>\n",
       "      <td>0.769537</td>\n",
       "      <td>0.576555</td>\n",
       "      <td>0.192982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-27</th>\n",
       "      <td>0.769507</td>\n",
       "      <td>0.612556</td>\n",
       "      <td>0.156951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>0.768379</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.186561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-19</th>\n",
       "      <td>0.768013</td>\n",
       "      <td>0.574822</td>\n",
       "      <td>0.193191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-17</th>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>0.194136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-21</th>\n",
       "      <td>0.765687</td>\n",
       "      <td>0.545671</td>\n",
       "      <td>0.220016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-12</th>\n",
       "      <td>0.764600</td>\n",
       "      <td>0.580413</td>\n",
       "      <td>0.184187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>0.764427</td>\n",
       "      <td>0.553360</td>\n",
       "      <td>0.211067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20</th>\n",
       "      <td>0.761006</td>\n",
       "      <td>0.541779</td>\n",
       "      <td>0.219227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-13</th>\n",
       "      <td>0.749405</td>\n",
       "      <td>0.547978</td>\n",
       "      <td>0.201427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-16</th>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.591767</td>\n",
       "      <td>0.153516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AccuracyPred  AccuracyBaseline  AccPred - AccBaseline\n",
       "Date                                                             \n",
       "2018-03-06      0.773123          0.566008               0.207115\n",
       "2018-01-18      0.772691          0.546172               0.226519\n",
       "2018-01-12      0.771654          0.558268               0.213386\n",
       "2018-01-10      0.771610          0.574941               0.196669\n",
       "2018-03-09      0.771610          0.553529               0.218081\n",
       "2018-04-17      0.771377          0.564356               0.207021\n",
       "2018-04-24      0.771300          0.579970               0.191330\n",
       "2018-02-05      0.770635          0.546825               0.223810\n",
       "2018-03-22      0.770324          0.558800               0.211523\n",
       "2018-03-19      0.769537          0.576555               0.192982\n",
       "2018-04-27      0.769507          0.612556               0.156951\n",
       "2018-02-02      0.768379          0.581818               0.186561\n",
       "2018-01-19      0.768013          0.574822               0.193191\n",
       "2018-01-17      0.767036          0.572900               0.194136\n",
       "2018-02-21      0.765687          0.545671               0.220016\n",
       "2018-04-12      0.764600          0.580413               0.184187\n",
       "2018-03-23      0.764427          0.553360               0.211067\n",
       "2018-04-20      0.761006          0.541779               0.219227\n",
       "2018-02-13      0.749405          0.547978               0.201427\n",
       "2018-03-16      0.745283          0.591767               0.153516"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.sort_values(by='AccuracyPred', ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
